{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a semantic search engine\n",
    "\n",
    "This tutorial will familiarize you with LangChain's document loader, embedding, and vector store abstractions. These abstractions are designed to support retrieval of data-- from (vector) databases and other sources-- for integration with LLM workflows. They are important for applications that fetch data to be reasoned over as part of model inference, as in the case of retrieval-augmented generation, or RAG (see our RAG tutorial here).\n",
    "\n",
    "Here we will build a search engine over a PDF document. This will allow us to retrieve passages in the PDF that are similar to an input query.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You will need to provision the following Azure resources:\n",
    "* Azure OpenAI with two models: GPT-4o and Embedding model.\n",
    "* Azure AI Search.\n",
    "You can run the terraform template from folder `../400_azure_ai_foundry` to create all of these resources by simply running the following commands.\n",
    "\n",
    "```sh\n",
    "terraform init\n",
    "terraform plan -out tfplan\n",
    "terraform apply tfplan\n",
    "```\n",
    "\n",
    "This tutorial requires the langchain-community and pypdf packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-community pypdf --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents and Document Loaders\n",
    "\n",
    "LangChain implements a Document abstraction, which is intended to represent a unit of text and associated metadata. It has three attributes:\n",
    "\n",
    "page_content: a string representing the content;\n",
    "metadata: a dict containing arbitrary metadata;\n",
    "id: (optional) a string identifier for the document.\n",
    "The metadata attribute can capture information about the source of the document, its relationship to other documents, and other information. Note that an individual Document object often represents a chunk of a larger document.\n",
    "\n",
    "We can generate sample documents when desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading documents\n",
    "\n",
    "Let's load a PDF into a sequence of Document objects. There is a sample PDF in the LangChain repo here -- a 10-k filing for Nike from 2023. We can consult the LangChain documentation for available PDF document loaders. Let's select PyPDFLoader, which is fairly lightweight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"./example_data/azure-for-architects.pdf\" #nke-10k-2023.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPDFLoader loads one Document object per PDF page. For each, we can easily access:\n",
    "\n",
    "* The string content of the page;\n",
    "* Metadata containing the file name and page number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ritesh Modi, Jack Lee, and Rithin Skaria\n",
      "Create secure, scalable, high-availability \n",
      "applications on the cloud\n",
      "Azure for Architects\n",
      "Third Edition\n",
      "\n",
      "{'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 16.0 (Windows)', 'creationdate': '2021-06-17T13:34:27+05:30', 'author': 'Ritesh Modi', 'moddate': '2021-06-17T14:21:14+05:30', 'subject': 'Create secure, scalable, high-availability applications on the cloud', 'title': 'Azure for Architects, Third Edition', 'trapped': '/False', 'source': './example_data/azure-for-architects.pdf', 'total_pages': 701, 'page': 1, 'page_label': 'a'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{docs[1].page_content[:200]}\\n\")\n",
    "print(docs[1].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting\n",
    "\n",
    "For both information retrieval and downstream question-answering purposes, a page may be too coarse a representation. Our goal in the end will be to retrieve `Document` objects that answer an input query, and further splitting our PDF will help ensure that the meanings of relevant portions of the document are not \"washed out\" by surrounding text.\n",
    "\n",
    "We can use text splitters for this purpose. Here we will use a simple text splitter that partitions based on characters. We will split our documents into chunks of 1000 characters with 200 characters of overlap between chunks. The overlap helps mitigate the possibility of separating a statement from important context related to it. We use the RecursiveCharacterTextSplitter, which will recursively split the document using common separators like new lines until each chunk is the appropriate size. This is the recommended text splitter for generic text use cases.\n",
    "\n",
    "We set `add_start_index=True` so that the character index where each split Document starts within the initial Document is preserved as metadata attribute “start_index”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits:  1473\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(\"Number of splits: \", len(all_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a sample split or chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='sender, stored in durable storage, and finally consumed by recipients.\n",
      "The top architectural concerns addressed by messaging patterns are as follows:\n",
      "• Durability: Messages are stored in durable storage, and applications can read \n",
      "them after they are received in case of a failover.\n",
      "• Reliability: Messages help implement reliability as they are persisted on disk and \n",
      "never lost.\n",
      "• Availability of messages: The messages are available for consumption by \n",
      "applications after the restoration of connectivity and before downtime.\n",
      "Azure provides Service Bus queues and topics to implement messaging patterns within \n",
      "applications. Azure Queue storage can also be used for the same purpose. \n",
      "Choosing between Azure Service Bus queues and Queue storage is about deciding on \n",
      "how long the message should be stored, the size of the message, latency, and cost. \n",
      "Azure Service Bus provides support for 256 KB messages, while Queue storage provides' metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 16.0 (Windows)', 'creationdate': '2021-06-17T13:34:27+05:30', 'author': 'Ritesh Modi', 'moddate': '2021-06-17T14:21:14+05:30', 'subject': 'Create secure, scalable, high-availability applications on the cloud', 'title': 'Azure for Architects, Third Edition', 'trapped': '/False', 'source': './example_data/azure-for-architects.pdf', 'total_pages': 701, 'page': 121, 'page_label': '89', 'start_index': 781}\n",
      "---------------\n",
      "page_content='how long the message should be stored, the size of the message, latency, and cost. \n",
      "Azure Service Bus provides support for 256 KB messages, while Queue storage provides \n",
      "support for 64 KB messages. Azure Service Bus can store messages for an unlimited \n",
      "period, while Queue storage can store messages for 7 days. The cost and latency are \n",
      "higher with Service Bus queues.\n",
      "Depending on your application's requirements and needs, the preceding factors \n",
      "should be considered before deciding on the best queue. In the next section, we will be \n",
      "discussing different types of messaging patterns.' metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 16.0 (Windows)', 'creationdate': '2021-06-17T13:34:27+05:30', 'author': 'Ritesh Modi', 'moddate': '2021-06-17T14:21:14+05:30', 'subject': 'Create secure, scalable, high-availability applications on the cloud', 'title': 'Azure for Architects, Third Edition', 'trapped': '/False', 'source': './example_data/azure-for-architects.pdf', 'total_pages': 701, 'page': 121, 'page_label': '89', 'start_index': 1550}\n"
     ]
    }
   ],
   "source": [
    "# print a sample chunk\n",
    "print(all_splits[309])\n",
    "print(\"---------------\")\n",
    "print(all_splits[310])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Vector search is a common way to store and search over unstructured data (such as unstructured text). The idea is to store numeric vectors that are associated with the text. Given a query, we can embed it as a vector of the same dimension and use vector similarity metrics (such as cosine similarity) to identify related text.\n",
    "\n",
    "LangChain supports embeddings from dozens of providers. These models specify how text should be converted into a numeric vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if os.path.exists(\".env\"):\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    openai_api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_EMBEDDING_API_VERSION\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of length 3072\n",
      "\n",
      "[0.010515968315303326, -0.01905210129916668, -0.017833741381764412, 0.022737640887498856, 0.008901641704142094, -0.006392581854015589, -0.011467811651527882, 0.024169212207198143, -0.0178185123950243, 0.02282901667058468]\n"
     ]
    }
   ],
   "source": [
    "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
    "print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with a model for generating text embeddings, we can next store them in a special data structure that supports efficient similarity search.\n",
    "\n",
    "## Vector stores\n",
    "\n",
    "LangChain VectorStore objects contain methods for adding text and `Document` objects to the store, and querying them using various similarity metrics. They are often initialized with embedding models, which determine how text data is translated to numeric vectors.\n",
    "\n",
    "LangChain includes a suite of integrations with different vector store technologies. Some vector stores are hosted by a provider (e.g., various cloud providers) and require specific credentials to use; some (such as Postgres) run in separate infrastructure that can be run locally or via a third-party; others can run in-memory for lightweight workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  azure-search-documents\n",
    "%pip install --upgrade --quiet  azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings, AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_EMBEDDING_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_SEARCH_SERVICE_ADMIN_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector store instance\n",
    "\n",
    "Create instance of the AzureSearch class using the embeddings from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: Request URL: 'https://search-service-52857-400001.search.windows.net/indexes('langchain-vector-demo')?api-version=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'api-key': 'REDACTED'\n",
      "    'Accept': 'application/json;odata.metadata=minimal'\n",
      "    'x-ms-client-request-id': '37393f1f-f392-11ef-8810-efa928428551'\n",
      "    'User-Agent': 'langchain azsdk-python-search-documents/11.5.2 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n",
      "No body was attached to the request\n",
      "INFO: Response status: 404\n",
      "Response headers:\n",
      "    'Cache-Control': 'no-cache,no-store'\n",
      "    'Pragma': 'no-cache'\n",
      "    'Content-Length': '136'\n",
      "    'Content-Type': 'application/json; charset=utf-8'\n",
      "    'Content-Language': 'REDACTED'\n",
      "    'Expires': '-1'\n",
      "    'Server': 'Microsoft-IIS/10.0'\n",
      "    'request-id': '37393f1f-f392-11ef-8810-efa928428551'\n",
      "    'elapsed-time': 'REDACTED'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Date': 'Tue, 25 Feb 2025 16:04:39 GMT'\n",
      "INFO: Request URL: 'https://search-service-52857-400001.search.windows.net/indexes?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '1065'\n",
      "    'api-key': 'REDACTED'\n",
      "    'Accept': 'application/json;odata.metadata=minimal'\n",
      "    'x-ms-client-request-id': '37832afe-f392-11ef-ae96-efa928428551'\n",
      "    'User-Agent': 'langchain azsdk-python-search-documents/11.5.2 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n",
      "A body is sent with the request\n",
      "INFO: Response status: 201\n",
      "Response headers:\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Content-Type': 'application/json; odata.metadata=minimal; odata.streaming=true; charset=utf-8'\n",
      "    'ETag': '\"0x8DD55B61C408E84\"'\n",
      "    'Location': 'REDACTED'\n",
      "    'Server': 'Microsoft-IIS/10.0'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Preference-Applied': 'REDACTED'\n",
      "    'OData-Version': 'REDACTED'\n",
      "    'request-id': '37832afe-f392-11ef-ae96-efa928428551'\n",
      "    'elapsed-time': 'REDACTED'\n",
      "    'Date': 'Tue, 25 Feb 2025 16:04:39 GMT'\n",
      "INFO: Request URL: 'https://search-service-52857-400001.search.windows.net/indexes('langchain-vector-demo')?api-version=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'api-key': 'REDACTED'\n",
      "    'Accept': 'application/json;odata.metadata=minimal'\n",
      "    'x-ms-client-request-id': '380a6d93-f392-11ef-a9c6-efa928428551'\n",
      "    'User-Agent': 'langchain azsdk-python-search-documents/11.5.2 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n",
      "No body was attached to the request\n",
      "INFO: Response status: 200\n",
      "Response headers:\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Content-Type': 'application/json; odata.metadata=minimal; odata.streaming=true; charset=utf-8'\n",
      "    'Content-Encoding': 'REDACTED'\n",
      "    'ETag': '\"0x8DD55B61C408E84\"'\n",
      "    'Vary': 'REDACTED'\n",
      "    'Server': 'Microsoft-IIS/10.0'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Preference-Applied': 'REDACTED'\n",
      "    'OData-Version': 'REDACTED'\n",
      "    'request-id': '380a6d93-f392-11ef-a9c6-efa928428551'\n",
      "    'elapsed-time': 'REDACTED'\n",
      "    'Date': 'Tue, 25 Feb 2025 16:04:40 GMT'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "# Specify additional properties for the Azure client such as the following https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core/README.md#configurations\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"],\n",
    "    azure_search_key=os.environ[\"AZURE_SEARCH_SERVICE_ADMIN_KEY\"],\n",
    "    index_name=os.environ[\"AZURE_SEARCH_SERVICE_INDEX\"],\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    # Configure max retries for the Azure client\n",
    "    additional_search_client_options={\"retry_total\": 3},\n",
    "    relevance_score_fn=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    "\n",
    "This step loads, chunks, and vectorizes the sample document, and then indexes the content into a search index on Azure AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: Retrying request to /embeddings in 9.000000 seconds\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: Retrying request to /embeddings in 9.000000 seconds\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO: Retrying request to /embeddings in 7.000000 seconds\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: Request URL: 'https://search-service-52857-400001.search.windows.net//indexes('langchain-vector-demo')/docs/search.index?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '2110579'\n",
      "    'api-key': 'REDACTED'\n",
      "    'Accept': 'application/json;odata.metadata=none'\n",
      "    'x-ms-client-request-id': '5def5e39-f392-11ef-81d6-efa928428551'\n",
      "    'User-Agent': 'langchain azsdk-python-search-documents/11.5.2 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n",
      "A body is sent with the request\n",
      "INFO: Response status: 200\n",
      "Response headers:\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
      "    'Content-Encoding': 'REDACTED'\n",
      "    'Vary': 'REDACTED'\n",
      "    'Server': 'Microsoft-IIS/10.0'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Preference-Applied': 'REDACTED'\n",
      "    'OData-Version': 'REDACTED'\n",
      "    'request-id': '5def5e39-f392-11ef-81d6-efa928428551'\n",
      "    'elapsed-time': 'REDACTED'\n",
      "    'Date': 'Tue, 25 Feb 2025 16:05:45 GMT'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ZjZkYmFlZTMtMGRhNS00NzBlLTlmNjQtMjQwZjE5ZjZiNmU2',\n",
       " 'YmM3MzIxN2MtYWRmNy00Y2QxLWE0MzEtZTgzNmRiZThiZTBl',\n",
       " 'MDlkOGY0YzktODU1Ni00YjVhLTkxNWMtNjliOWU4MjI5YzQ5',\n",
       " 'NmUxNjRkNDUtY2FlMi00NGFhLThmM2QtMjUxODY5ZjY4Mzhl',\n",
       " 'ZDY1OTUwNjYtNjg3My00ZDkwLTk1ZDgtYmYyN2JhMDM1ODM4',\n",
       " 'N2RhMzkwMzEtOGRhNi00MGJhLTkyODktNTI1MjAxNWI4OGMz',\n",
       " 'MjVmOGQ5YjAtNjQ5Yi00NjFkLThmMTUtODY0MmZmNGYwN2Ew',\n",
       " 'MmU0NmQ3M2QtYzYyOS00MjZhLThiYmItZDMxZjFjN2Q3YmE2',\n",
       " 'NDdmMDgzYWMtMjhlOS00ZDUyLWJmZTQtYjdhMTE2YzllMzBi',\n",
       " 'OWJhMDg0MzktMGY3YS00ZWQ1LThiYjctNTRjNzE0Y2VmNWYy',\n",
       " 'YjNkNmYyMTAtYjU1ZC00YTQzLWE1MDEtZjI2YjcwZTdjZmZi',\n",
       " 'MzU1ZGMwYmQtZDI4Mi00NmYyLWIzOGQtMWE0NmI0ZWY2YWI3',\n",
       " 'ZTc4ODg3OGMtMmI5NS00YTBjLWFiN2EtZTNhNWNiMTA3Njlj',\n",
       " 'MGQxZTJjMjYtMWZkNi00MGU2LThkODAtMWM3M2E5YjM1OTQw',\n",
       " 'NGIwMWUzN2QtMTM3Yi00OTc0LWFjODktMzJjMDA1NGRkNmRl',\n",
       " 'ODkyMWVmZTUtMTMxOS00MWVjLWE0YjItYzg3YTNmMWFiNmZj',\n",
       " 'MzMwNDNhMDEtMGEzMy00NzZiLWFjZTktODkyODdlODdlZDYw',\n",
       " 'ZTc4YWQ3MmUtYzVlOC00YmY0LTk2MDMtODlkMzFlMjU4YTdi',\n",
       " 'MTkwZWNlOGYtNmZjMC00ZTRlLWE0YTctMjk1MWQzYzQzZDA0',\n",
       " 'NjA5MWNjZDUtMjcxNi00ZTIyLTgyNTgtYWQyNjExYTc5YmY0',\n",
       " 'YzAwMTllODctYTVjOC00NzkxLTlmOGUtMTlkNGU0YzQ4NzJi',\n",
       " 'Njc5MDBmMmEtZjJjMy00NGQ2LTk5NzctMmIxM2MxNjYxMWRj',\n",
       " 'YjM2NjQ2OGMtNzA0Ni00NzMwLWIzNzAtMDg5ODIzMDIzODBi',\n",
       " 'YTRmYzljODEtNjM2MS00MDJlLWJjMjktZDc3MWY0MzQxOTk3',\n",
       " 'NzBkNTUwYTItMGE4MC00OTUzLTliYmMtYjlkZmQ5ZTUyNDU3',\n",
       " 'ZTQ0YjgxNWMtNGY5My00ZTQxLWE1ZDQtN2FlNGRhMDdkZmE2',\n",
       " 'NDZlZDUyY2ItZWRmYy00N2Y5LTlhMTQtNGE0ODAzYWNjMDgx',\n",
       " 'NTdmMzIzY2MtNTY4Yy00YzYxLWI5YTAtMGZjMTczZmM4ODIx',\n",
       " 'NjRlMjI1MDktZTc2Mi00YzQ2LThkODktOTUzZDBmYTUwOTQ5',\n",
       " 'ODAzODczMjctYTc0Yy00NDQ1LWJhNGItNTI4ZDEyMDk5ODQ3']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=all_splits[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've instantiated a VectorStore that contains documents, we can query it. VectorStore includes methods for querying:\n",
    "\n",
    "* Synchronously and asynchronously;\n",
    "* By string query and by vector;\n",
    "* With and without returning similarity scores;\n",
    "* By similarity and maximum marginal relevance (to balance similarity with query to diversity in retrieved results).\n",
    "\n",
    "## Perform a vector similarity search\n",
    "\n",
    "Execute a pure vector similarity search using the `similarity_search()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: Request URL: 'https://search-service-52857-400001.search.windows.net//indexes('langchain-vector-demo')/docs/search.post.search?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '68917'\n",
      "    'api-key': 'REDACTED'\n",
      "    'Accept': 'application/json;odata.metadata=none'\n",
      "    'x-ms-client-request-id': '685ef788-f392-11ef-9981-efa928428551'\n",
      "    'User-Agent': 'langchain azsdk-python-search-documents/11.5.2 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n",
      "A body is sent with the request\n",
      "INFO: Response status: 200\n",
      "Response headers:\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
      "    'Content-Encoding': 'REDACTED'\n",
      "    'Vary': 'REDACTED'\n",
      "    'Server': 'Microsoft-IIS/10.0'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Preference-Applied': 'REDACTED'\n",
      "    'OData-Version': 'REDACTED'\n",
      "    'request-id': '685ef788-f392-11ef-9981-efa928428551'\n",
      "    'elapsed-time': 'REDACTED'\n",
      "    'Date': 'Tue, 25 Feb 2025 16:06:01 GMT'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ritesh Modi, Jack Lee, and Rithin Skaria\n",
      "Create secure, scalable, high-availability \n",
      "applications on the cloud\n",
      "Azure for Architects\n",
      "Third Edition\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"Who are the authors of the book Azure for Architects\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search with relevance scores\n",
    "\n",
    "Execute a pure vector similarity search using the `similarity_search_with_relevance_scores()` method. Queries that don't meet the threshold requirements are exluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: Request URL: 'https://search-service-52857-400001.search.windows.net//indexes('langchain-vector-demo')/docs/search.post.search?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '68881'\n",
      "    'api-key': 'REDACTED'\n",
      "    'Accept': 'application/json;odata.metadata=none'\n",
      "    'x-ms-client-request-id': '30ef14cf-f393-11ef-b7dc-efa928428551'\n",
      "    'User-Agent': 'langchain azsdk-python-search-documents/11.5.2 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n",
      "A body is sent with the request\n",
      "INFO: Response status: 200\n",
      "Response headers:\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
      "    'Content-Encoding': 'REDACTED'\n",
      "    'Vary': 'REDACTED'\n",
      "    'Server': 'Microsoft-IIS/10.0'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Preference-Applied': 'REDACTED'\n",
      "    'OData-Version': 'REDACTED'\n",
      "    'request-id': '30ef14cf-f393-11ef-b7dc-efa928428551'\n",
      "    'elapsed-time': 'REDACTED'\n",
      "    'Date': 'Tue, 25 Feb 2025 16:11:38 GMT'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(metadata={'id': 'ZjZkYmFlZTMtMGRhNS00NzBlLTlmNjQtMjQwZjE5ZjZiNmU2', 'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 16.0 (Windows)', 'creationdate': '2021-06-17T13:34:27+05:30', 'author': 'Ritesh Modi', 'moddate': '2021-06-17T14:21:14+05:30', 'subject': 'Create secure, scalable, high-availability applications on the cloud', 'title': 'Azure for Architects, Third Edition', 'trapped': '/False', 'source': './example_data/azure-for-architects.pdf', 'total_pages': 701, 'page': 1, 'page_label': 'a', 'start_index': 0}, page_content='Ritesh Modi, Jack Lee, and Rithin Skaria\\nCreate secure, scalable, high-availability \\napplications on the cloud\\nAzure for Architects\\nThird Edition'),\n",
      "  0.77486813),\n",
      " (Document(metadata={'id': 'YmM3MzIxN2MtYWRmNy00Y2QxLWE0MzEtZTgzNmRiZThiZTBl', 'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 16.0 (Windows)', 'creationdate': '2021-06-17T13:34:27+05:30', 'author': 'Ritesh Modi', 'moddate': '2021-06-17T14:21:14+05:30', 'subject': 'Create secure, scalable, high-availability applications on the cloud', 'title': 'Azure for Architects, Third Edition', 'trapped': '/False', 'source': './example_data/azure-for-architects.pdf', 'total_pages': 701, 'page': 2, 'page_label': 'b', 'start_index': 0}, page_content='Azure for Architects Third Edition\\nCopyright © 2020 Packt Publishing\\nAll rights reserved. No part of this book may be reproduced, stored in a retrieval system, \\nor transmitted in any form or by any means, without the prior written permission of the \\npublisher, except in the case of brief quotations embedded in critical articles or reviews.\\nEvery effort has been made in the preparation of this book to ensure the accuracy of \\nthe information presented. However, the information contained in this book is sold \\nwithout warranty, either express or implied. Neither the authors, nor Packt Publishing, \\nand its dealers and distributors will be held liable for any damages caused or alleged to \\nbe caused directly or indirectly by this book.\\nPackt Publishing has endeavored to provide trademark information about all of the \\ncompanies and products mentioned in this book by the appropriate use of capitals. \\nHowever, Packt Publishing cannot guarantee the accuracy of this information.'),\n",
      "  0.7312372)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "docs_and_scores = vector_store.similarity_search_with_relevance_scores(\n",
    "    query=\"Who are the authors of the book Azure for Architects\",\n",
    "    k=4,\n",
    "    score_threshold=0.70,\n",
    ")\n",
    "\n",
    "pprint(docs_and_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a hybrid search\n",
    "\n",
    "Execute hybrid search using the search_type or hybrid_search() method. Vector and nonvector text fields are queried in parallel, results are merged, and top matches of the unified result set are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: Request URL: 'https://search-service-52857-400001.search.windows.net//indexes('langchain-vector-demo')/docs/search.post.search?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '68969'\n",
      "    'api-key': 'REDACTED'\n",
      "    'Accept': 'application/json;odata.metadata=none'\n",
      "    'x-ms-client-request-id': '7f94bc39-f392-11ef-9c14-efa928428551'\n",
      "    'User-Agent': 'langchain azsdk-python-search-documents/11.5.2 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n",
      "A body is sent with the request\n",
      "INFO: Response status: 200\n",
      "Response headers:\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
      "    'Content-Encoding': 'REDACTED'\n",
      "    'Vary': 'REDACTED'\n",
      "    'Server': 'Microsoft-IIS/10.0'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Preference-Applied': 'REDACTED'\n",
      "    'OData-Version': 'REDACTED'\n",
      "    'request-id': '7f94bc39-f392-11ef-9c14-efa928428551'\n",
      "    'elapsed-time': 'REDACTED'\n",
      "    'Date': 'Tue, 25 Feb 2025 16:06:40 GMT'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure for Architects Third Edition\n",
      "Copyright © 2020 Packt Publishing\n",
      "All rights reserved. No part of this book may be reproduced, stored in a retrieval system, \n",
      "or transmitted in any form or by any means, without the prior written permission of the \n",
      "publisher, except in the case of brief quotations embedded in critical articles or reviews.\n",
      "Every effort has been made in the preparation of this book to ensure the accuracy of \n",
      "the information presented. However, the information contained in this book is sold \n",
      "without warranty, either express or implied. Neither the authors, nor Packt Publishing, \n",
      "and its dealers and distributors will be held liable for any damages caused or alleged to \n",
      "be caused directly or indirectly by this book.\n",
      "Packt Publishing has endeavored to provide trademark information about all of the \n",
      "companies and products mentioned in this book by the appropriate use of capitals. \n",
      "However, Packt Publishing cannot guarantee the accuracy of this information.\n"
     ]
    }
   ],
   "source": [
    "# Perform a hybrid search using the search_type parameter\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"Who are the authors of the book Azure for Architects\",\n",
    "    k=3,\n",
    "    search_type=\"hybrid\",\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Async query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: Request URL: 'https://search-service-52857-400001.search.windows.net//indexes('langchain-vector-demo')/docs/search.post.search?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '68980'\n",
      "    'api-key': 'REDACTED'\n",
      "    'Accept': 'application/json;odata.metadata=none'\n",
      "    'x-ms-client-request-id': 'bc0210da-f392-11ef-99b4-efa928428551'\n",
      "    'User-Agent': 'langchain azsdk-python-search-documents/11.5.2 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n",
      "A body is sent with the request\n",
      "INFO: Response status: 200\n",
      "Response headers:\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
      "    'Content-Encoding': 'REDACTED'\n",
      "    'Vary': 'REDACTED'\n",
      "    'Server': 'Microsoft-IIS/10.0'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Preference-Applied': 'REDACTED'\n",
      "    'OData-Version': 'REDACTED'\n",
      "    'request-id': 'bc0210da-f392-11ef-99b4-efa928428551'\n",
      "    'elapsed-time': 'REDACTED'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Date': 'Tue, 25 Feb 2025 16:08:22 GMT'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='companies and products mentioned in this book by the appropriate use of capitals. \n",
      "However, Packt Publishing cannot guarantee the accuracy of this information.\n",
      "Authors: Ritesh Modi, Jack Lee, and Rithin Skaria\n",
      "Technical Reviewers: Melony Qin and Sanjeev Kumar\n",
      "Managing Editors: Aditya Datar and Afzal Shaikh\n",
      "Acquisitions Editor: Shrilekha Inani\n",
      "Production Editors: Ganesh Bhadwalkar and Deepak Chavan\n",
      "Editorial Board: Vishal Bodwani, Ben Renow-Clarke, Edward Doxey, Joanne Lovell,  \n",
      "Arijit Sarkar, and Dominic Shakeshaft\n",
      "First Edition: October 2017\n",
      "Second Edition: January 2019\n",
      "Third Edition: June 2020\n",
      "Production Reference: 3260620\n",
      "ISBN: 978-1-83921-586-5\n",
      "Published by Packt Publishing Ltd.\n",
      "Livery Place, 35 Livery Street\n",
      "Birmingham B3 2PB, UK' metadata={'id': 'MDlkOGY0YzktODU1Ni00YjVhLTkxNWMtNjliOWU4MjI5YzQ5', 'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 16.0 (Windows)', 'creationdate': '2021-06-17T13:34:27+05:30', 'author': 'Ritesh Modi', 'moddate': '2021-06-17T14:21:14+05:30', 'subject': 'Create secure, scalable, high-availability applications on the cloud', 'title': 'Azure for Architects, Third Edition', 'trapped': '/False', 'source': './example_data/azure-for-architects.pdf', 'total_pages': 701, 'page': 2, 'page_label': 'b', 'start_index': 822}\n"
     ]
    }
   ],
   "source": [
    "results = await vector_store.asimilarity_search(\"When was this book published ?\")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval and Generation\n",
    "\n",
    "Now let’s write the actual application logic. We want to create a simple application that takes a user question, searches for documents relevant to that question, passes the retrieved documents and initial question to a model, and returns an answer.\n",
    "\n",
    "For generation, we will use the chat model selected at the start of the tutorial.\n",
    "\n",
    "We’ll use a prompt for RAG that is checked into the LangChain prompt hub (here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.74-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph) (0.3.39)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.3.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.6)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
      "Requirement already satisfied: anyio in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Downloading langgraph-0.2.74-py3-none-any.whl (151 kB)\n",
      "Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
      "Downloading langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-win_amd64.whl (75 kB)\n",
      "Installing collected packages: msgpack, langgraph-sdk, langgraph-checkpoint, langgraph\n",
      "Successfully installed langgraph-0.2.74 langgraph-checkpoint-2.0.16 langgraph-sdk-0.1.53 msgpack-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langsmith\\client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain import hub\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    openai_api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: Request URL: 'https://search-service-52857-400001.search.windows.net//indexes('langchain-vector-demo')/docs/search.post.search?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '69017'\n",
      "    'api-key': 'REDACTED'\n",
      "    'Accept': 'application/json;odata.metadata=none'\n",
      "    'x-ms-client-request-id': '72ced0be-f3a4-11ef-ac9a-efa928428551'\n",
      "    'User-Agent': 'langchain azsdk-python-search-documents/11.5.2 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n",
      "A body is sent with the request\n",
      "INFO: Response status: 200\n",
      "Response headers:\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
      "    'Content-Encoding': 'REDACTED'\n",
      "    'Vary': 'REDACTED'\n",
      "    'Server': 'Microsoft-IIS/10.0'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Preference-Applied': 'REDACTED'\n",
      "    'OData-Version': 'REDACTED'\n",
      "    'request-id': '72ced0be-f3a4-11ef-ac9a-efa928428551'\n",
      "    'elapsed-time': 'REDACTED'\n",
      "    'Date': 'Tue, 25 Feb 2025 18:15:10 GMT'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatPromptValue' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39msimilarity_search(question)\n\u001b[0;32m      4\u001b[0m docs_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m retrieved_docs)\n\u001b[1;32m----> 5\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs_content})\n\u001b[0;32m      6\u001b[0m answer \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(prompt)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:891\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ChatPromptValue' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "question = \"Who are the authors of the book Azure for Architects and when it was published ?\"\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question)\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "prompt = prompt.invoke({\"question\": question, \"context\": docs_content})\n",
    "answer = llm.invoke(prompt)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n",
      "INFO: Request URL: 'https://search-service-52857-400001.search.windows.net//indexes('langchain-vector-demo')/docs/search.post.search?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '69017'\n",
      "    'api-key': 'REDACTED'\n",
      "    'Accept': 'application/json;odata.metadata=none'\n",
      "    'x-ms-client-request-id': '77dcd462-f3a4-11ef-82f0-efa928428551'\n",
      "    'User-Agent': 'langchain azsdk-python-search-documents/11.5.2 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n",
      "A body is sent with the request\n",
      "INFO: Response status: 200\n",
      "Response headers:\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Content-Type': 'application/json; odata.metadata=none; odata.streaming=true; charset=utf-8'\n",
      "    'Content-Encoding': 'REDACTED'\n",
      "    'Vary': 'REDACTED'\n",
      "    'Server': 'Microsoft-IIS/10.0'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'Preference-Applied': 'REDACTED'\n",
      "    'OData-Version': 'REDACTED'\n",
      "    'request-id': '77dcd462-f3a4-11ef-82f0-efa928428551'\n",
      "    'elapsed-time': 'REDACTED'\n",
      "    'Date': 'Tue, 25 Feb 2025 18:15:18 GMT'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatPromptValue' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m graph_builder\u001b[38;5;241m.\u001b[39madd_edge(START, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieve\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph_builder\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m---> 29\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWho are the authors of the book Azure for Architects and when it was published ?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContext: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2124\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2123\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2124\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1779\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1777\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1779\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1782\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1783\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1785\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:546\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    543\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    544\u001b[0m )\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:310\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 310\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[82], line 19\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(state: State):\n\u001b[0;32m     18\u001b[0m     docs_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 19\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs_content})\n\u001b[0;32m     20\u001b[0m     response \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(messages)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39mcontent}\n",
      "File \u001b[1;32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:891\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ChatPromptValue' object has no attribute 'invoke'",
      "\u001b[0mDuring task with name 'generate' and id '345224e8-cc07-951e-4350-16b3cc21b68b'"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "response = graph.invoke({\"question\": \"Who are the authors of the book Azure for Architects and when it was published ?\"})\n",
    "\n",
    "print(f'Context: {response[\"context\"]}\\n\\n')\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph also comes with built-in utilities for visualizing the control flow of your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚠️Consider it here the end of the lab. THE FOLLOWING IS NOT WORKING ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return documents based on similarity to an embedded query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://ai-services-52857-400001.cognitiveservices.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-01 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m embedding \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39membed_query(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow many chapters in this book ?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_by_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(results[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:659\u001b[0m, in \u001b[0;36mVectorStore.similarity_search_by_vector\u001b[1;34m(self, embedding, k, **kwargs)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search_by_vector\u001b[39m(\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28mself\u001b[39m, embedding: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m], k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    648\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[0;32m    649\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to embedding vector.\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \n\u001b[0;32m    651\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query vector.\u001b[39;00m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding = embeddings.embed_query(\"How many chapters in this book ?\")\n",
    "\n",
    "results = vector_store.similarity_search_by_vector(embedding)\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout analysis and extraction of text from images\n",
    "\n",
    "If you require a more granular segmentation of text (e.g., into distinct paragraphs, titles, tables, or other structures) or require extraction of text from images, the method below is appropriate. It will return a list of Document objects, where each object represents a structure on the page. The Document's metadata stores the page number and other information related to the object (e.g., it might store table rows and columns in the case of a table object).\n",
    "\n",
    "Under the hood it uses the langchain-unstructured library. See the integration docs for more information about using Unstructured with LangChain.\n",
    "\n",
    "Unstructured supports multiple parameters for PDF parsing:\n",
    "\n",
    "* strategy (e.g., \"fast\" or \"hi-res\")\n",
    "* API or local processing. You will need an API key to use the API.\n",
    "\n",
    "The hi-res strategy provides support for document layout analysis and OCR. We demonstrate it below via the API. See local parsing section below for considerations when running locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"langchain-unstructured[local]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test unstructured\n",
    "# %pip install unstructured\n",
    "# %pip install \"unstructured[pdf]\"\n",
    "# Install package, compatible with API partitioning\n",
    "# %pip install --upgrade --quiet langchain-unstructured unstructured-client unstructured \"unstructured[pdf]\" python-magic\n",
    "# %pip install onnx\n",
    "# %pip install libmagic poppler libreoffice pandoc tesseract\n",
    "# %pip install \"unstructured[all-docs]\" \n",
    "%pip install libmagic-dev poppler-utils tesseract-ocr libreoffice pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "\n",
    "elements = partition(filename=\"./example_data/azure-for-architects.pdf\")\n",
    "print(\"\\n\\n\".join([str(el) for el in elements]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "file_paths = [\n",
    "    \"./example_data/azure-for-architects.pdf\",\n",
    "    # \"./example_data/state_of_the_union.txt\",\n",
    "]\n",
    "\n",
    "\n",
    "loader = UnstructuredLoader(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "\n",
    "elements = partition(filename=\"./example_data/azure-for-architects.pdf\")\n",
    "\n",
    "print(\"\\n\\n\".join([str(el) for el in elements]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
