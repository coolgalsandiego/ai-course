{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting metrics and logs from Azure API Management\n",
    "\n",
    "## Built-in logging and metrics\n",
    "\n",
    "Playground to try the [buil-in logging capabilities of API Management](https://learn.microsoft.com/en-us/azure/api-management/observability). The requests are logged into Application Insights and it's easy to track request/response details and token usage with provided [notebook](openai-usage-analysis-workbook.json).\n",
    "\n",
    "This is also to try the [emit token metric policy](https://learn.microsoft.com/en-us/azure/api-management/azure-openai-emit-token-metric-policy). The policy sends metrics to Application Insights about consumption of large language model tokens through Azure OpenAI Service APIs.\n",
    "\n",
    "![](images/built-in-logging.gif)\n",
    "\n",
    "Notes:\n",
    "- Token count metrics include: Total Tokens, Prompt Tokens, and Completion Tokens.\n",
    "- This policy supports OpenAI response streaming! Use the [streaming tool](../../tools/streaming.ipynb) to test and troubleshoot response streaming.\n",
    "- Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior and troubleshoot the [policy](policy.xml).\n",
    "\n",
    "[View policy configuration](policy.xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 1️⃣ Create deployment using Terraform\n",
    "\n",
    "This lab uses Terraform to declaratively define all the resources that will be deployed. Change the [variables.tf](variables.tf) directly to try different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! $env:ARM_SUBSCRIPTION_ID=(az account show --query id -o tsv)   # if using Windows PowerShell\n",
    "# ! setenv ARM_SUBSCRIPTION_ID=$(az account show --query id -o tsv) # if using macOS or Linux\n",
    "\n",
    "! terraform init\n",
    "! terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following resources should be created.\n",
    "![](images/resources.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3️⃣ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉🏻 APIM Resource Gateway URL:  https://apim-genai-330.azure-api.net\n",
      "👉🏻 Application Insights App ID:  cfd51794-ee37-4b68-bef3-545f29999084\n",
      "👉🏻 APIM Subscription Key 1:  db4dffd4ab0349bb8a89ffbe44197fce\n",
      "👉🏻 APIM Subscription Key 2:  50348efdb74e47d5b0a32cd692c46987\n",
      "👉🏻 APIM Subscription Key 3:  5a610f0ad3be4827a51bc2cc796e216c\n",
      "👉🏻 Resource Group Name:  rg-apim-genai-openai-330\n",
      "👉🏻 Application Insights Resource Name:  app-insights\n"
     ]
    }
   ],
   "source": [
    "apim_resource_gateway_url = ! terraform output -raw apim_resource_gateway_url\n",
    "apim_resource_gateway_url = apim_resource_gateway_url.n\n",
    "print(\"👉🏻 APIM Resource Gateway URL: \", apim_resource_gateway_url)\n",
    "\n",
    "app_insights_app_id = ! terraform output -raw app_insights_app_id\n",
    "app_insights_app_id = app_insights_app_id.n\n",
    "print(\"👉🏻 Application Insights App ID: \", app_insights_app_id)\n",
    "\n",
    "apim_subscription_key_1 = ! terraform output -raw apim_subscription_key_1\n",
    "apim_subscription_key_1 = apim_subscription_key_1.n\n",
    "print(\"👉🏻 APIM Subscription Key 1: \", apim_subscription_key_1)\n",
    "\n",
    "apim_subscription_key_2 = ! terraform output -raw apim_subscription_key_2\n",
    "apim_subscription_key_2 = apim_subscription_key_2.n\n",
    "print(\"👉🏻 APIM Subscription Key 2: \", apim_subscription_key_2)\n",
    "\n",
    "apim_subscription_key_3 = ! terraform output -raw apim_subscription_key_3\n",
    "apim_subscription_key_3 = apim_subscription_key_3.n\n",
    "print(\"👉🏻 APIM Subscription Key 3: \", apim_subscription_key_3)\n",
    "\n",
    "resource_group_name = ! terraform output -raw resource_group_name\n",
    "resource_group_name = resource_group_name.n\n",
    "print(\"👉🏻 Resource Group Name: \", resource_group_name)\n",
    "\n",
    "app_insights_resource_name = ! terraform output -raw app_insights_resource_name\n",
    "app_insights_resource_name = app_insights_resource_name.n\n",
    "print(\"👉🏻 Application Insights Resource Name: \", app_insights_resource_name)\n",
    "\n",
    "openai_api_version = \"2024-10-21\"\n",
    "openai_model_name = \"gpt-4o\"\n",
    "openai_deployment_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### 🧪 Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses. \n",
    "\n",
    "You will not see HTTP 429s returned as API Management's `retry` policy will select an available backend. If no backends are viable, an HTTP 503 will be returned.\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior of the backend pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Run: 1 / 10\n",
      "⌚ 4.04 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Tue, 28 Jan 2025 20:28:12 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'dffa8c7b-b890-4b48-b1f1-58bb072977d9', 'X-Content-Type-Options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'a561f1aa-dda5-4a71-b63d-8d668770d005', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '19', 'x-ratelimit-remaining-tokens': '19340', 'azureml-model-session': 'd007-20250114101137', 'x-envoy-upstream-service-time': '818', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:cfd51794-ee37-4b68-bef3-545f29999084'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 73} \n",
      "\n",
      "💬  Oh sure, let me just consult my magical non-existent clock for you. Oh wait, I forgot—I can't tell the time. Why not try looking at literally every device around you? Revolutionary idea, I know. \n",
      "\n",
      "▶️ Run: 2 / 10\n",
      "⌚ 1.41 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Tue, 28 Jan 2025 20:28:13 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '74a557fa-9c04-4080-ac3b-6d8f150acc0b', 'X-Content-Type-Options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '3df5a168-b33f-47ac-a9c4-ef6e067f0f78', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '18', 'x-ratelimit-remaining-tokens': '18680', 'azureml-model-session': 'd003-20250114053715', 'x-envoy-upstream-service-time': '1131', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:cfd51794-ee37-4b68-bef3-545f29999084'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 66} \n",
      "\n",
      "💬  Oh sure, let me just consult my magical non-existent clock for you. Oh wait, I can't actually tell time—guess you'll have to look at your own device, genius! \n",
      "\n",
      "▶️ Run: 3 / 10\n",
      "⌚ 0.78 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Tue, 28 Jan 2025 20:28:13 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '55c5624b-6636-45d0-a640-94a777f77356', 'X-Content-Type-Options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '27f94c57-4180-4935-b83c-bd1a3f3723e0', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '17', 'x-ratelimit-remaining-tokens': '18020', 'azureml-model-session': 'd009-20250114150206', 'x-envoy-upstream-service-time': '534', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:cfd51794-ee37-4b68-bef3-545f29999084'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 64} \n",
      "\n",
      "💬  Oh sure, let me just activate my magical time-telling powers... oh wait, I don't have any. Look at the clock like the rest of us peasants. \n",
      "\n",
      "▶️ Run: 4 / 10\n",
      "⌚ 0.99 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Tue, 28 Jan 2025 20:28:15 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '55c0448b-9f4f-4dfc-8a20-6a8404ee2e8c', 'X-Content-Type-Options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'dce02b9f-c859-4bee-968a-d34fc3bca853', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '16', 'x-ratelimit-remaining-tokens': '17360', 'azureml-model-session': 'd001-20250114003751', 'x-envoy-upstream-service-time': '743', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:cfd51794-ee37-4b68-bef3-545f29999084'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 73} \n",
      "\n",
      "💬  Oh sure, let me consult my magical time-telling powers! Oh wait, I forgot—I’m not a clock. Guess you'll just have to look at your phone like everyone else in the 21st century. \n",
      "\n",
      "▶️ Run: 5 / 10\n",
      "⌚ 1.64 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Tue, 28 Jan 2025 20:28:17 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '09e54e00-6798-4ed9-b88a-3751710c68b4', 'X-Content-Type-Options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'aa222dcf-0cd2-4447-a11c-c5fb4b5d1332', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '15', 'x-ratelimit-remaining-tokens': '16700', 'azureml-model-session': 'd003-20250114053715', 'x-envoy-upstream-service-time': '1390', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:cfd51794-ee37-4b68-bef3-545f29999084'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 73} \n",
      "\n",
      "💬  Oh sure, let me just tap into my imaginary clock that somehow knows where you are because, clearly, I can read minds too. Why don't you just look at a clock or your phone like a normal person? \n",
      "\n",
      "▶️ Run: 6 / 10\n",
      "⌚ 0.99 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Tue, 28 Jan 2025 20:28:18 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '7374ca29-ad63-4e15-8bfb-81dd5da7b22e', 'X-Content-Type-Options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '4f5b3a1e-33c7-4d8c-922d-be02f8259509', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '14', 'x-ratelimit-remaining-tokens': '16040', 'azureml-model-session': 'd005-20250114075211', 'x-envoy-upstream-service-time': '760', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:cfd51794-ee37-4b68-bef3-545f29999084'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 69} \n",
      "\n",
      "💬  Oh sure, let me just consult my magical Time-O-Matic... Oh wait, you have a clock on literally every device around you. Check one of those genius inventions, why don't you? \n",
      "\n",
      "▶️ Run: 7 / 10\n",
      "⌚ 0.59 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Tue, 28 Jan 2025 20:28:18 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'e668cd76-950c-4863-a695-72ade40ea956', 'X-Content-Type-Options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '03ea7de5-4685-48f5-8299-c1a06ebb1ae8', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '13', 'x-ratelimit-remaining-tokens': '15380', 'azureml-model-session': 'd002-20250114014405', 'x-envoy-upstream-service-time': '349', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:cfd51794-ee37-4b68-bef3-545f29999084'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 33, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 63} \n",
      "\n",
      "💬  Oh, sure! Let me just check my magical, non-existent clock for you. Oh wait, I don't have one. Try looking at your phone, genius. \n",
      "\n",
      "▶️ Run: 8 / 10\n",
      "⌚ 0.80 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Tue, 28 Jan 2025 20:28:19 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'a3bfa155-9e6a-4b14-b1de-9f06c5d6530d', 'X-Content-Type-Options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '8cee35ba-6616-4d4c-ba1d-8af074df9797', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '12', 'x-ratelimit-remaining-tokens': '14720', 'azureml-model-session': 'd009-20250114150206', 'x-envoy-upstream-service-time': '532', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:cfd51794-ee37-4b68-bef3-545f29999084'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 68} \n",
      "\n",
      "💬  Oh sure, let me just consult my magical time-telling abilities. Oh wait, I forgot—I’m not a clock. Guess you’ll have to figure that out yourself. Good luck! \n",
      "\n",
      "▶️ Run: 9 / 10\n",
      "⌚ 0.68 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Tue, 28 Jan 2025 20:28:19 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '1a447883-99dd-44fb-aea6-e5863bc6a425', 'X-Content-Type-Options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'e97092d9-bc92-455a-a121-c812cf1d10be', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '11', 'x-ratelimit-remaining-tokens': '14060', 'azureml-model-session': 'd008-20250114111847', 'x-envoy-upstream-service-time': '442', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:cfd51794-ee37-4b68-bef3-545f29999084'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 55} \n",
      "\n",
      "💬  Oh, sure, let me just consult my invisible watch that totally works! It's exactly \"figure-it-out-yourself o'clock.\" \n",
      "\n",
      "▶️ Run: 10 / 10\n",
      "⌚ 0.78 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Tue, 28 Jan 2025 20:28:20 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '09e68bdd-05e1-4f0a-8b50-b182f5110699', 'X-Content-Type-Options': 'nosniff', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '4db3d5b7-c65d-47e0-be04-d76ec3ce0968', 'x-ms-region': 'Sweden Central', 'x-ratelimit-remaining-requests': '10', 'x-ratelimit-remaining-tokens': '13400', 'azureml-model-session': 'd009-20250114150206', 'x-envoy-upstream-service-time': '547', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:cfd51794-ee37-4b68-bef3-545f29999084'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 68} \n",
      "\n",
      "💬  Oh, sure, because I totally have a built-in clock just for you. Why not stare at your device for the time you’re using to talk to me instead? So much easier! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "runs = 10\n",
    "url = apim_resource_gateway_url + \"/openai/deployments/\" + openai_deployment_name + \"/chat/completions?api-version=\" + openai_api_version\n",
    "api_runs = []\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"▶️ Run:\", i+1, \"/\", runs)\n",
    "    \n",
    "\n",
    "    messages={\"messages\":[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]}\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, headers = {'api-key':apim_subscription_key_1}, json = messages)\n",
    "    response_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"⌚ {response_time:.2f} seconds\")\n",
    "    # Check the response status code and apply formatting\n",
    "    if 200 <= response.status_code < 300:\n",
    "        status_code_str = '\\x1b[1;32m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and green\n",
    "    elif response.status_code >= 400:\n",
    "        status_code_str = '\\x1b[1;31m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and red\n",
    "    else:\n",
    "        status_code_str = str(response.status_code)  # No formatting\n",
    "\n",
    "    # Print the response status with the appropriate formatting\n",
    "    print(\"Response status:\", status_code_str)\n",
    "    \n",
    "    print(\"Response headers:\", response.headers)\n",
    "    \n",
    "    if \"x-ms-region\" in response.headers:\n",
    "        print(\"x-ms-region:\", '\\x1b[1;31m'+response.headers.get(\"x-ms-region\")+'\\x1b[0m') # this header is useful to determine the region of the backend that served the request\n",
    "        api_runs.append((response_time, response.headers.get(\"x-ms-region\")))\n",
    "    \n",
    "    if (response.status_code == 200):\n",
    "        data = json.loads(response.text)\n",
    "        print(\"Token usage:\", data.get(\"usage\"), \"\\n\")\n",
    "        print(\"💬 \", data.get(\"choices\")[0].get(\"message\").get(\"content\"), \"\\n\")\n",
    "    else:\n",
    "        print(response.text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### 🧪 Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Run:  1\n",
      "⌚ 0.69 seconds\n",
      "💬  Oh sure, let me just consult my crystal ball... Oh wait, it's broken. Why not check a clock like the highly advanced human you are?\n",
      "▶️ Run:  2\n",
      "⌚ 0.63 seconds\n",
      "💬  Oh sure, let me just grab my non-existent watch and tell you. Spoiler alert: it’s \"time to get your own clock.\"\n",
      "▶️ Run:  3\n",
      "⌚ 1.37 seconds\n",
      "💬  Oh sure, let me just consult my magical time-telling crystal ball—that I totally have. Wait a sec... Nope, it’s broken. Guess you'll have to look at literally anything else that tells time.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "runs = 3\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"▶️ Run: \", i+1)\n",
    "\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=apim_resource_gateway_url,\n",
    "        api_key=apim_subscription_key_3,\n",
    "        api_version=openai_api_version\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages)\n",
    "    \n",
    "    response_time = time.time() - start_time\n",
    "    print(f\"⌚ {response_time:.2f} seconds\")\n",
    "    print(\"💬 \", response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### 🔍 Analyze Application Insights requests\n",
    "\n",
    "With this query you can get the request and response details including the prompt and the OpenAI completion. It also returns token counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>apiName</th>\n",
       "      <th>apimSubscription</th>\n",
       "      <th>duration</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>model</th>\n",
       "      <th>messages</th>\n",
       "      <th>completion</th>\n",
       "      <th>region</th>\n",
       "      <th>promptTokens</th>\n",
       "      <th>completionTokens</th>\n",
       "      <th>totalTokens</th>\n",
       "      <th>remainingTokens</th>\n",
       "      <th>remainingRequests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-28T20:28:54.9551699Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>c43d9b01-290e-4e43-9941-6178cfad08fd</td>\n",
       "      <td>1143.39</td>\n",
       "      <td>AzureOpenAI/Python 1.41.0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh sure, let me just consult my magical time-t...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>72</td>\n",
       "      <td>11420</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-28T20:28:53.7633397Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>c43d9b01-290e-4e43-9941-6178cfad08fd</td>\n",
       "      <td>409.92</td>\n",
       "      <td>AzureOpenAI/Python 1.41.0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh sure, let me just grab my non-existent watc...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "      <td>12080</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-28T20:28:52.5601924Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>c43d9b01-290e-4e43-9941-6178cfad08fd</td>\n",
       "      <td>433.89</td>\n",
       "      <td>AzureOpenAI/Python 1.41.0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh sure, let me just consult my crystal ball.....</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>12740</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-28T20:28:20.3240797Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>580.06</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh, sure, because I totally have a built-in cl...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>68</td>\n",
       "      <td>13400</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-28T20:28:19.6286636Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>481.25</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh, sure, let me just consult my invisible wat...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>14060</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-28T20:28:18.8623472Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>567.00</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh sure, let me just consult my magical time-t...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>68</td>\n",
       "      <td>14720</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-01-28T20:28:18.2489058Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>383.15</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh, sure! Let me just check my magical, non-ex...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>63</td>\n",
       "      <td>15380</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-01-28T20:28:17.24887Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>797.85</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh sure, let me just consult my magical Time-O...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>69</td>\n",
       "      <td>16040</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-01-28T20:28:15.6237887Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>1422.42</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh sure, let me just tap into my imaginary clo...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>16700</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-01-28T20:28:14.6327346Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>779.90</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh sure, let me consult my magical time-tellin...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>17360</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-01-28T20:28:13.8591668Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>567.85</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh sure, let me just activate my magical time-...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>18020</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-01-28T20:28:12.4518056Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>1189.34</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh sure, let me just consult my magical non-ex...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>66</td>\n",
       "      <td>18680</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-01-28T20:28:09.5805999Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>2627.99</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td>Oh sure, let me just consult my magical non-ex...</td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>19340</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       timestamp           apiName  \\\n",
       "0   2025-01-28T20:28:54.9551699Z  api-azure-openai   \n",
       "1   2025-01-28T20:28:53.7633397Z  api-azure-openai   \n",
       "2   2025-01-28T20:28:52.5601924Z  api-azure-openai   \n",
       "3   2025-01-28T20:28:20.3240797Z  api-azure-openai   \n",
       "4   2025-01-28T20:28:19.6286636Z  api-azure-openai   \n",
       "5   2025-01-28T20:28:18.8623472Z  api-azure-openai   \n",
       "6   2025-01-28T20:28:18.2489058Z  api-azure-openai   \n",
       "7     2025-01-28T20:28:17.24887Z  api-azure-openai   \n",
       "8   2025-01-28T20:28:15.6237887Z  api-azure-openai   \n",
       "9   2025-01-28T20:28:14.6327346Z  api-azure-openai   \n",
       "10  2025-01-28T20:28:13.8591668Z  api-azure-openai   \n",
       "11  2025-01-28T20:28:12.4518056Z  api-azure-openai   \n",
       "12  2025-01-28T20:28:09.5805999Z  api-azure-openai   \n",
       "\n",
       "                        apimSubscription  duration                  userAgent  \\\n",
       "0   c43d9b01-290e-4e43-9941-6178cfad08fd   1143.39  AzureOpenAI/Python 1.41.0   \n",
       "1   c43d9b01-290e-4e43-9941-6178cfad08fd    409.92  AzureOpenAI/Python 1.41.0   \n",
       "2   c43d9b01-290e-4e43-9941-6178cfad08fd    433.89  AzureOpenAI/Python 1.41.0   \n",
       "3   492fda85-596c-4b95-9e9d-bcde843e6a5a    580.06     python-requests/2.32.3   \n",
       "4   492fda85-596c-4b95-9e9d-bcde843e6a5a    481.25     python-requests/2.32.3   \n",
       "5   492fda85-596c-4b95-9e9d-bcde843e6a5a    567.00     python-requests/2.32.3   \n",
       "6   492fda85-596c-4b95-9e9d-bcde843e6a5a    383.15     python-requests/2.32.3   \n",
       "7   492fda85-596c-4b95-9e9d-bcde843e6a5a    797.85     python-requests/2.32.3   \n",
       "8   492fda85-596c-4b95-9e9d-bcde843e6a5a   1422.42     python-requests/2.32.3   \n",
       "9   492fda85-596c-4b95-9e9d-bcde843e6a5a    779.90     python-requests/2.32.3   \n",
       "10  492fda85-596c-4b95-9e9d-bcde843e6a5a    567.85     python-requests/2.32.3   \n",
       "11  492fda85-596c-4b95-9e9d-bcde843e6a5a   1189.34     python-requests/2.32.3   \n",
       "12  492fda85-596c-4b95-9e9d-bcde843e6a5a   2627.99     python-requests/2.32.3   \n",
       "\n",
       "     model                                           messages  \\\n",
       "0   gpt-4o  [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "1   gpt-4o  [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "2   gpt-4o  [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "3           [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "4           [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "5           [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "6           [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "7           [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "8           [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "9           [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "10          [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "11          [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "12          [{\"role\":\"system\",\"content\":\"You are a sarcast...   \n",
       "\n",
       "                                           completion          region  \\\n",
       "0   Oh sure, let me just consult my magical time-t...  Sweden Central   \n",
       "1   Oh sure, let me just grab my non-existent watc...  Sweden Central   \n",
       "2   Oh sure, let me just consult my crystal ball.....  Sweden Central   \n",
       "3   Oh, sure, because I totally have a built-in cl...  Sweden Central   \n",
       "4   Oh, sure, let me just consult my invisible wat...  Sweden Central   \n",
       "5   Oh sure, let me just consult my magical time-t...  Sweden Central   \n",
       "6   Oh, sure! Let me just check my magical, non-ex...  Sweden Central   \n",
       "7   Oh sure, let me just consult my magical Time-O...  Sweden Central   \n",
       "8   Oh sure, let me just tap into my imaginary clo...  Sweden Central   \n",
       "9   Oh sure, let me consult my magical time-tellin...  Sweden Central   \n",
       "10  Oh sure, let me just activate my magical time-...  Sweden Central   \n",
       "11  Oh sure, let me just consult my magical non-ex...  Sweden Central   \n",
       "12  Oh sure, let me just consult my magical non-ex...  Sweden Central   \n",
       "\n",
       "   promptTokens completionTokens totalTokens remainingTokens remainingRequests  \n",
       "0            30               42          72           11420                17  \n",
       "1            30               29          59           12080                18  \n",
       "2            30               30          60           12740                19  \n",
       "3            30               38          68           13400                10  \n",
       "4            30               25          55           14060                11  \n",
       "5            30               38          68           14720                12  \n",
       "6            30               33          63           15380                13  \n",
       "7            30               39          69           16040                14  \n",
       "8            30               43          73           16700                15  \n",
       "9            30               43          73           17360                16  \n",
       "10           30               34          64           18020                17  \n",
       "11           30               36          66           18680                18  \n",
       "12           30               43          73           19340                19  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"requests  \\\n",
    "| project timestamp, duration, customDimensions \\\n",
    "| extend duration = round(duration, 2) \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend apiName = tostring(parsedCustomDimensions.['API Name']) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription Name']) \\\n",
    "| extend userAgent = tostring(parsedCustomDimensions.['Request-User-agent']) \\\n",
    "| extend request_json = tostring(parsedCustomDimensions.['Request-Body']) \\\n",
    "| extend request = parse_json(request_json) \\\n",
    "| extend model = tostring(request.['model']) \\\n",
    "| extend messages = tostring(request.['messages']) \\\n",
    "| extend region = tostring(parsedCustomDimensions.['Response-x-ms-region']) \\\n",
    "| extend remainingTokens = tostring(parsedCustomDimensions.['Response-x-ratelimit-remaining-tokens']) \\\n",
    "| extend remainingRequests = tostring(parsedCustomDimensions.['Response-x-ratelimit-remaining-requests']) \\\n",
    "| extend response_json = tostring(parsedCustomDimensions.['Response-Body']) \\\n",
    "| extend response = parse_json(response_json) \\\n",
    "| extend promptTokens = tostring(response.['usage'].['prompt_tokens']) \\\n",
    "| extend completionTokens = tostring(response.['usage'].['completion_tokens']) \\\n",
    "| extend totalTokens = tostring(response.['usage'].['total_tokens']) \\\n",
    "| extend completion = tostring(response.['choices'][0].['message'].['content']) \\\n",
    "| project timestamp, apiName, apimSubscription, duration, userAgent, model, messages, completion, region, promptTokens, completionTokens, totalTokens, remainingTokens, remainingRequests \\\n",
    "| order by timestamp desc\" + \"\\\"\"\n",
    "\n",
    "result_stdout = !  az monitor app-insights query --app {app_insights_app_id} --analytics-query {query} \n",
    "result = json.loads(result_stdout.n)\n",
    "\n",
    "table = result.get('tables')[0]\n",
    "pd.DataFrame(table.get(\"rows\"), columns=[col.get(\"name\") for col in table.get('columns')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='portal'></a>\n",
    "### 🔍 Open the workbook in the Azure Portal\n",
    "\n",
    "Go to the application insights resource and under the Monitoring section select the Workbooks blade. You should see the OpenAI Usage Analysis workbook with the above query and some others to check token counts, performance, failures, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### 🧪 Execute multiple runs for each subscription using the Azure OpenAI Python SDK\n",
    "\n",
    "We will send requests for each subscription. Adjust the number of `runs` to your test scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Run:  1\n",
      "💬  for subscription 1:  Oh, absolutely! Let me just consult my magical, non-existent watch that runs on pure vibes. Yep, it's currently *who knows o'clock*! You're welcome.\n",
      "💬  for subscription 2:  Oh, sure, let me check my invisible watch for you. Oh wait, I forgot—I’m not your clock. Try looking at, I don’t know, any device around you? Revolutionary idea, I know.\n",
      "💬  for subscription 3:  Oh, sure, let me just magically pull a clock out of thin air for you. Would you like me to predict the future too, or is that enough? Why not just look at the thing literally every device around you shows—THE TIME.\n",
      "▶️ Run:  2\n",
      "💬  for subscription 1:  Oh, sure, let me just consult my imaginary watch that runs on fairy dust. Yeah, no clue. Maybe try asking a clock?\n",
      "💬  for subscription 2:  Oh sure, let me just consult my imaginary watch. Yep, it's precisely \"figure-it-out-yourself\" o'clock.\n",
      "💬  for subscription 3:  Oh, sure! Let me just consult my magical time-telling powers that don't exist. Why don't you look at a clock? Revolutionary, I know.\n",
      "▶️ Run:  3\n",
      "💬  for subscription 1:  Wow, what a groundbreaking question! Too bad I’m not a clock. Try looking at your phone—life-changing, I know.\n",
      "💬  for subscription 2:  Oh sure, let me just reach into my pocket sundial real quick. Wait... oh no, I don’t have pockets because I’m a virtual assistant. Guess you’ll have to check for yourself.\n",
      "💬  for subscription 3:  Oh sure, let me just consult my imaginary watch. Oh no... it’s broken! Guess you'll have to rely on one of the million clocks around you. Good luck with that.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "runs = 3\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"▶️ Run: \", i+1)\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription_key_1, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"💬 \",\"for subscription 1: \", response.choices[0].message.content)\n",
    "\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription_key_2, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"💬 \",\"for subscription 2: \", response.choices[0].message.content)\n",
    "\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription_key_3, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"💬 \",\"for subscription 3: \", response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### 🔍 Analyze Application Insights custom metrics with a KQL query\n",
    "\n",
    "With this query you can get the custom metrics that were emitted by Azure APIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>clientIP</th>\n",
       "      <th>apiId</th>\n",
       "      <th>apimSubscription</th>\n",
       "      <th>UserId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20:28</td>\n",
       "      <td>672</td>\n",
       "      <td>176.177.25.47</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20:28</td>\n",
       "      <td>191</td>\n",
       "      <td>176.177.25.47</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>c43d9b01-290e-4e43-9941-6178cfad08fd</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20:35</td>\n",
       "      <td>141</td>\n",
       "      <td>176.177.25.47</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>c43d9b01-290e-4e43-9941-6178cfad08fd</td>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20:35</td>\n",
       "      <td>199</td>\n",
       "      <td>176.177.25.47</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>a62ca781-d4f2-4f1b-bb49-0416b0352d70</td>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20:35</td>\n",
       "      <td>178</td>\n",
       "      <td>176.177.25.47</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>492fda85-596c-4b95-9e9d-bcde843e6a5a</td>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20:36</td>\n",
       "      <td>67</td>\n",
       "      <td>176.177.25.47</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>c43d9b01-290e-4e43-9941-6178cfad08fd</td>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp  value       clientIP             apiId  \\\n",
       "0     20:28    672  176.177.25.47  api-azure-openai   \n",
       "1     20:28    191  176.177.25.47  api-azure-openai   \n",
       "2     20:35    141  176.177.25.47  api-azure-openai   \n",
       "3     20:35    199  176.177.25.47  api-azure-openai   \n",
       "4     20:35    178  176.177.25.47  api-azure-openai   \n",
       "5     20:36     67  176.177.25.47  api-azure-openai   \n",
       "\n",
       "                       apimSubscription UserId  \n",
       "0  492fda85-596c-4b95-9e9d-bcde843e6a5a    N/A  \n",
       "1  c43d9b01-290e-4e43-9941-6178cfad08fd    N/A  \n",
       "2  c43d9b01-290e-4e43-9941-6178cfad08fd   alex  \n",
       "3  a62ca781-d4f2-4f1b-bb49-0416b0352d70   alex  \n",
       "4  492fda85-596c-4b95-9e9d-bcde843e6a5a   alex  \n",
       "5  c43d9b01-290e-4e43-9941-6178cfad08fd   alex  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "query = \"\\\"\" + \"customMetrics  \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend clientIP = tostring(parsedCustomDimensions.['Client IP']) \\\n",
    "| extend apiId = tostring(parsedCustomDimensions.['API ID']) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| extend UserId = tostring(parsedCustomDimensions.['User ID']) \\\n",
    "| project timestamp, value, clientIP, apiId, apimSubscription, UserId \\\n",
    "| order by timestamp asc\" + \"\\\"\"\n",
    "\n",
    "result_stdout = ! az monitor app-insights query --app {app_insights_resource_name} -g {resource_group_name} --analytics-query {query} \n",
    "result = json.loads(result_stdout.n)\n",
    "\n",
    "table = result.get('tables')[0]\n",
    "df = pd.DataFrame(table.get(\"rows\"), columns=[col.get(\"name\") for col in table.get('columns')])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%H:%M')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 See the metrics on the Azure Portal\n",
    "\n",
    "Open the Application Insights resource, navigate to the Metrics blade, then select the defined namespace (openai). Choose the metric \"Total Tokens\" with a Sum aggregation. Then, apply splitting by 'Subscription Id' to view values for each dimension.\n",
    "\n",
    "![result](images/result.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View logs and metrics on Azure Managed Grafana dashboard\n",
    "\n",
    "You can also view the logs and metrics on the Azure Managed Grafana dashboard. Navigate to the Azure Managed Grafana. Login, then go to the dashboards section. Then import the following 2 dashboards:\n",
    "1. Dashboard with ID : 16604 to view logs and metrics from API Management.\n",
    "2. Dashboard from JSON file [./grafana-dashboard-apim-openai.json](./grafana-dashboard-apim-openai.json) to view logs and metrics from Application Insights.\n",
    "   Alternatively, you can also import the dashbord from the [Grafana dashboard ID: 22552](https://grafana.com/grafana/dashboards/22552).\n",
    "\n",
    "![](images/grafana-dashboard-openai.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
