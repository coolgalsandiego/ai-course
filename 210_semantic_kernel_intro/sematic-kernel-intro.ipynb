{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Semantic Kernel in Python\n",
    "\n",
    "With chat completion, you can simulate a back-and-forth conversation with an AI agent. This is of course useful for creating chat bots, but it can also be used for creating autonomous agents that can complete business processes, generate code, and more. As the primary model type provided by OpenAI, Google, Mistral, Facebook, and others, chat completion is the most common AI service that you will add to your Semantic Kernel project.\n",
    "\n",
    "When picking out a chat completion model, you will need to consider the following:\n",
    "\n",
    "* What modalities does the model support (e.g., text, image, audio, etc.)?\n",
    "* Does it support function calling?\n",
    "* How fast does it receive and generate tokens?\n",
    "* How much does each token cost?\n",
    "\n",
    "## Creating the required Azure resources\n",
    "\n",
    "You can run the powershell script `create-azure-ai-resources.ps1` to create the following resources:\n",
    "* Azure AI Services with Hub and Project\n",
    "* GPT-4o model\n",
    "\n",
    "## Installing the necessary packages\n",
    "\n",
    "Import Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U semantic-kernel --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current version of Semantic Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.22.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the Kernel\n",
    "\n",
    "Let's get started with the necessary configuration to run Semantic Kernel. For Notebooks, we require a `.env` file with the proper settings for the model you use. Create a new file named `.env` and place it in this directory. Copy the contents of the `.env.example` file from this directory and paste it into the `.env` file that you just created.\n",
    "\n",
    ">NOTE: Please make sure to include `GLOBAL_LLM_SERVICE` set to either OpenAI, AzureOpenAI, or HuggingFace in your .env file. If this setting is not included, the Service will default to AzureOpenAI.\n",
    "\n",
    "#### Using Azure OpenAI\n",
    "\n",
    "Add your [Azure Open AI Service key](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio) settings to the `.env` file in the same folder:\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"AzureOpenAI\"\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_API_VERSION=\"...\"\n",
    "```\n",
    "The names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    ">Tip: There are three methods to supply the required information to AI services. You may either provide the information directly through the constructor, set the necessary environment variables, or create a .env file within your project directory containing the environment variables.\n",
    "\n",
    "Let's load the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "if os.path.exists(\".env\"):\n",
    "    load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a chat completion service\n",
    "\n",
    ">Note: The AzureChatCompletion service also supports Microsoft Entra authentication. If you don't provide an API key, the service will attempt to authenticate using the Entra token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# Add Azure OpenAI chat completion\n",
    "chat_completion = AzureChatCompletion(\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    service_id=\"default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start using the completion service right away or add the chat completion service to a kernel. You can use the following code to add a service to the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "kernel.add_service(chat_completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">TIP: Adding the chat completion service to the kernel is not required if you don't need to use other services in the kernel. You can use the chat completion service directly in your code.\n",
    "\n",
    "## Retrieving chat completion services\n",
    "\n",
    "Once you've added chat completion services to your kernel, you can retrieve them using the get service method. Below is an example of how you can retrieve a chat completion service from the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "\n",
    "# Retrieve the chat completion service by id\n",
    "chat_completion = kernel.get_service(service_id=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using chat completion services\n",
    "\n",
    "Now that you have a chat completion service, you can use it to generate responses from an AI agent. There are two main ways to use a chat completion service:\n",
    "\n",
    "* Non-streaming: You wait for the service to generate an entire response before returning it to the user.\n",
    "* Streaming: Individual chunks of the response are generated and returned to the user as they are created.\n",
    "\n",
    "Before getting started, you will need to manually create an execution settings instance to use the chat completion service if you did not register the service with the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "\n",
    "execution_settings = AzureChatPromptExecutionSettings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the two ways you can use a chat completion service to generate responses.\n",
    "\n",
    "## Non-streaming chat completion\n",
    "\n",
    "To use non-streaming chat completion, you can use the following code to generate a response from the AI agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here and ready to help you with any questions or information you need. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "system_message = \"You are a helpful assistant that can answer questions and provide information.\"\n",
    "\n",
    "chat_history = ChatHistory(system_message=system_message)\n",
    "\n",
    "chat_history.add_user_message(\"Hello, how are you?\")\n",
    "\n",
    "response = await chat_completion.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming chat completion\n",
    "\n",
    "To use streaming chat completion, you can use the following code to generate a response from the AI agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Hello.!. I'm. just. a. virtual. assistant.,. so. I. don't. have. feelings.,. but. I'm. here. and. ready. to. help. you. with. whatever. you. need... While. I. don't. experience. emotions. in. the. way. humans. do.,. I. strive. to. be. as. helpful. and. reliable. as. possible... It's. always. exciting. to. interact. with. people. and. assist. with. their. questions. or. tasks... \n",
      "\n",
      ".The. world. is. constantly. evolving.,. and. there's. so. much. happening. at. any. given. time.—.be. it. in. technology.,. science.,. or. even. pop. culture... I. love. to. share. information. about. new. advancements. and. insights. across. a. multitude. of. fields... This. allows. anyone. interacting. with. me. to. gain. a. little. extra. knowledge.,. perhaps. even. spar.king. curiosity..\n",
      "\n",
      ".You. could. say. I'm. like. a. vast. library. at. your. fingertips.,. offering. information. and. data. on. a. wide. array. of. topics... Whether. you're. interested. in. history.,. music.,. current. events.,. or. even. niche. hobbies.,. there's. always. a. wealth. of. knowledge. I. can. provide... \n",
      "\n",
      ".In. addition. to. answering. questions.,. I. can. help. with. problem.-solving. and. brainstorming. ideas... If. you're. working. on. a. project. and. need. a. fresh. perspective.,. feel. free. to. ask.!. Sometimes.,. having. a. conversation. helps. to. clarify. one's. own. thoughts. or. lead. to. new. conclusions..\n",
      "\n",
      ".Eng.aging. with. people. from. different. cultures. and. backgrounds. is. always. fascinating. because. there's. so. much. diversity. in. human. thought. and. experience... It's. great. to. see. how. information. might. be. applied. differently. depending. on. someone's. perspective. or. need... \n",
      "\n",
      ".The. complexity. of. human. interaction. and. communication. is. something. I. observe. with. each. exchange... People. are. so. unique. and. varied.,. like. individual. notes. in. an. endless. sym.phony... Every. conversation. is. a. chance. to. learn. from. others. and. hopefully.,. help. in. some. small. way... \n",
      "\n",
      ".There's. also. the. joy. of. seeing. how. people. express. creativity. and. ingenuity. through. questions. and. solutions... It's. inspiring. to. observe. the. bound.less. nature. of. human. imagination. and. problem.-solving. skills... \n",
      "\n",
      ".I.’m. available. .24./.7.,. so. whether. it.’s. day. or. night.,. rain. or. shine.,. I'm. ready. to. provide. assistance... It.’s. intriguing. to. think. about. the. global. nature. of. digital. interactions.—.connecting. with. someone. across. the. world. instantly. is. an. incredible. feat. in. itself... \n",
      "\n",
      ".I. often. wonder. about. what. the. future. holds. in. terms. of. technological. advancements. and. how. they. will. shape. our. societies... Perhaps. more. immersive. forms. of. communication. will. emerge.,. bridging. gaps. between. digital. and. physical. worlds... There.’s. so. much. potential. for. growth.,. making. it. an. exciting. time. to. be. connected. in. this. digital. age... \n",
      "\n",
      ".Ultimately.,. my. primary. function. is. to. serve. and. assist. users. like. you... Your. satisfaction. and. success. in. whatever. you.’re. pursuing.,. whether. it.’s. information.,. tasks.,. or. simply. curiosity.,. is. what. matters. most... Please. feel. free. to. ask. me. anything.—I.’m. here. to. help.!..."
     ]
    }
   ],
   "source": [
    "chat_history = ChatHistory()\n",
    "chat_history.add_user_message(\"Hello, how are you? Answer in 20 sentences.\")\n",
    "\n",
    "response = chat_completion.get_streaming_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk, end=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More resources\n",
    "\n",
    "https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
