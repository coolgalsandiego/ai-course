{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ❤️ OpenAI\n",
    "\n",
    "## Backend pool Load Balancing lab\n",
    "![flow](images/backend-pool-load-balancing.gif)\n",
    "\n",
    "Playground to try the built-in load balancing [backend pool functionality of APIM](https://learn.microsoft.com/en-us/azure/api-management/backends?tabs=bicep) to either a list of Azure OpenAI endpoints or mock servers.\n",
    "\n",
    "Notes:\n",
    "- The backend pool uses round-robin by default\n",
    "- But priority and weight based routing are also supported: Adjust the `priority` (the lower the number, the higher the priority) and `weight` parameters in the `openai_resources` variable\n",
    "- The `retry` API Management policy initiates a retry to an available backend if an HTTP 429 status code is encountered\n",
    "\n",
    "### Result\n",
    "![result](images/result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2️⃣ Create deployment using Terraform\n",
    "\n",
    "This lab uses Terraform to declaratively define all the resources that will be deployed. Change the [variables.tf](variables.tf) directly to try different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\n",
      "- Reusing previous version of azure/azapi from the dependency lock file\n",
      "- Reusing previous version of hashicorp/azurerm from the dependency lock file\n",
      "- Using previously-installed azure/azapi v2.1.0\n",
      "- Using previously-installed hashicorp/azurerm v4.14.0\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\n",
      "\u001b[0m\u001b[32m\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
      "any changes that are required for your infrastructure. All Terraform commands\n",
      "should now work.\n",
      "\n",
      "If you ever set or change modules or backend configuration for Terraform,\n",
      "rerun this command to reinitialize your working directory. If you forget, other\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\n",
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mazurerm_resource_group.rg: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_ai_services.ai-services[\"openai-uks\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.CognitiveServices/accounts/openai-uks]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_ai_services.ai-services[\"openai-frc\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.CognitiveServices/accounts/openai-frc]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_ai_services.ai-services[\"openai-swc\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.CognitiveServices/accounts/openai-swc]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_log_analytics_workspace.log-analytics: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.OperationalInsights/workspaces/log-analytics-310-pprod]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management.apim: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_application_insights.app-insights: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.Insights/components/app-insights]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_api.api-azure-openai: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/apis/api-azure-openai;rev=1]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_backend.openai[\"openai-uks\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/backends/openai-uks]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_backend.openai[\"openai-frc\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/backends/openai-frc]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_backend.openai[\"openai-swc\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/backends/openai-swc]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_role_assignment.Cognitive-Services-OpenAI-User[\"openai-swc\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.CognitiveServices/accounts/openai-swc/providers/Microsoft.Authorization/roleAssignments/ee7d624f-0800-b6f7-dbb3-6c200c17be13]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_role_assignment.Cognitive-Services-OpenAI-User[\"openai-uks\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.CognitiveServices/accounts/openai-uks/providers/Microsoft.Authorization/roleAssignments/0d82a6dc-04a4-920a-44f8-27eb847c206d]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_cognitive_deployment.gpt-4o[\"openai-uks\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.CognitiveServices/accounts/openai-uks/deployments/gpt-4o]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_cognitive_deployment.gpt-4o[\"openai-swc\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.CognitiveServices/accounts/openai-swc/deployments/gpt-4o]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_cognitive_deployment.gpt-4o[\"openai-frc\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.CognitiveServices/accounts/openai-frc/deployments/gpt-4o]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_role_assignment.Cognitive-Services-OpenAI-User[\"openai-frc\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.CognitiveServices/accounts/openai-frc/providers/Microsoft.Authorization/roleAssignments/9c550741-9126-9ee3-d1a0-027978fea220]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_subscription.apim-subscription-3: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/subscriptions/85781582-010d-4366-a541-3748c9409349]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_subscription.apim-subscription-1: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/subscriptions/78908010-4c60-49f2-a557-ba1882582619]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_subscription.openai-subscription: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/subscriptions/c2a9500f-4cf8-4b5d-b18e-64f5854962e1]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_subscription.apim-subscription-2: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/subscriptions/59e56e07-6136-4295-8c40-f22310bf29ab]\u001b[0m\n",
      "\u001b[0m\u001b[1mazapi_update_resource.apim-backend-circuit-breaker[\"openai-uks\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/backends/openai-uks]\u001b[0m\n",
      "\u001b[0m\u001b[1mazapi_resource.apim-backend-pool: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/backends/openai-backend-pool]\u001b[0m\n",
      "\u001b[0m\u001b[1mazapi_update_resource.apim-backend-circuit-breaker[\"openai-frc\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/backends/openai-frc]\u001b[0m\n",
      "\u001b[0m\u001b[1mazapi_update_resource.apim-backend-circuit-breaker[\"openai-swc\"]: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/backends/openai-swc]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_logger.apim-logger: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/loggers/apim-logger]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_application_insights_workbook.workbook: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.Insights/workbooks/85b3e8bb-fc93-40be-83f2-98f6bec18ba0]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_diagnostic.apim-diagnostic: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/diagnostics/applicationinsights]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_api_diagnostic.apim-api-diagnostic: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/apis/api-azure-openai/diagnostics/applicationinsights]\u001b[0m\n",
      "\u001b[0m\u001b[1mazurerm_api_management_api_policy.policy: Refreshing state... [id=/subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/rg-apim-genai-310-pprod/providers/Microsoft.ApiManagement/service/apim-external-310-pprod/apis/api-azure-openai]\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[32mNo changes.\u001b[0m\u001b[1m Your infrastructure matches the configuration.\u001b[0m\n",
      "\n",
      "\u001b[0mTerraform has compared your real infrastructure against your configuration\n",
      "and found no differences, so no changes are needed.\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Apply complete! Resources: 0 added, 0 changed, 0 destroyed.\n",
      "\u001b[0m\u001b[0m\u001b[1m\u001b[32m\n",
      "Outputs:\n",
      "\n",
      "\u001b[0mapim_resource_gateway_url = \"https://apim-external-310-pprod.azure-api.net\"\n",
      "apim_subscription_key = <sensitive>\n",
      "apim_subscription_key_1 = <sensitive>\n",
      "apim_subscription_key_2 = <sensitive>\n",
      "apim_subscription_key_3 = <sensitive>\n",
      "app_insights_app_id = \"a64417ff-2c09-4df6-af5b-cc041b515ddb\"\n"
     ]
    }
   ],
   "source": [
    "! terraform init\n",
    "! terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### 🧪 Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉🏻 APIM Resource Gateway URL:  https://apim-external-310-pprod.azure-api.net\n",
      "👉🏻 APIM Subscription Key:  3b1e080b883b4c55a19c2a0a0826454b\n",
      "👉🏻 Application Insights App ID:  a64417ff-2c09-4df6-af5b-cc041b515ddb\n",
      "👉🏻 APIM Subscription Key 1:  2d28576f0914447d9b5003ec8ae02fbe\n",
      "👉🏻 APIM Subscription Key 2:  f3e8efcfed6e45d78c5463889d292812\n",
      "👉🏻 APIM Subscription Key 3:  d8a61c5a8c024ac49ca2db2095fa5c69\n"
     ]
    }
   ],
   "source": [
    "apim_resource_gateway_url = ! terraform output -raw apim_resource_gateway_url\n",
    "apim_resource_gateway_url = apim_resource_gateway_url.n\n",
    "print(\"👉🏻 APIM Resource Gateway URL: \", apim_resource_gateway_url)\n",
    "\n",
    "apim_subscription_key = ! terraform output -raw apim_subscription_key\n",
    "apim_subscription_key = apim_subscription_key.n\n",
    "print(\"👉🏻 APIM Subscription Key: \", apim_subscription_key)\n",
    "\n",
    "app_insights_app_id = ! terraform output -raw app_insights_app_id\n",
    "app_insights_app_id = app_insights_app_id.n\n",
    "print(\"👉🏻 Application Insights App ID: \", app_insights_app_id)\n",
    "\n",
    "apim_subscription_key_1 = ! terraform output -raw apim_subscription_key_1\n",
    "apim_subscription_key_1 = apim_subscription_key_1.n\n",
    "print(\"👉🏻 APIM Subscription Key 1: \", apim_subscription_key_1)\n",
    "\n",
    "apim_subscription_key_2 = ! terraform output -raw apim_subscription_key_2\n",
    "apim_subscription_key_2 = apim_subscription_key_2.n\n",
    "print(\"👉🏻 APIM Subscription Key 2: \", apim_subscription_key_2)\n",
    "\n",
    "apim_subscription_key_3 = ! terraform output -raw apim_subscription_key_3\n",
    "apim_subscription_key_3 = apim_subscription_key_3.n\n",
    "print(\"👉🏻 APIM Subscription Key 3: \", apim_subscription_key_3)\n",
    "\n",
    "openai_api_version = \"2024-10-21\"\n",
    "openai_model_name = \"gpt-4o\"\n",
    "openai_deployment_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### 🧪 Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses. \n",
    "\n",
    "You will not see HTTP 429s returned as API Management's `retry` policy will select an available backend. If no backends are viable, an HTTP 503 will be returned.\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior of the backend pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Run: 1 / 20\n",
      "⌚ 0.87 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:46 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '7c7c7242-f4ec-45fe-b912-c81880617c0a', 'x-ratelimit-remaining-requests': '77', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '5912d73b-a4c0-4e53-9489-fb4c9f07f19e', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd199-20241121123626', 'x-ms-region': 'Sweden Central', 'x-envoy-upstream-service-time': '594', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '6020', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 47, 'prompt_tokens': 30, 'total_tokens': 77} \n",
      "\n",
      "💬  Oh, absolutely! Let me just use my nonexistent superpowers to check a clock! But sadly, since I'm stuck in this text box and frozen in time, I can't help you there. Maybe try looking at a device that can? \n",
      "\n",
      "▶️ Run: 2 / 20\n",
      "⌚ 1.26 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:47 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'aa67bb1a-6163-4340-970e-16a6d7f31a0c', 'x-ratelimit-remaining-requests': '76', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'b69b3e17-cab6-42ee-a3c8-5c401f06d590', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd065-20241120171340', 'x-ms-region': 'France Central', 'x-envoy-upstream-service-time': '943', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '5360', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mFrance Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 46, 'prompt_tokens': 30, 'total_tokens': 76} \n",
      "\n",
      "💬  Oh sure, let me just look at my non-existent watch... or maybe my crystal ball. I can't actually tell you the current time, but I bet there’s a clock somewhere around you or maybe a device that shows it! \n",
      "\n",
      "▶️ Run: 3 / 20\n",
      "⌚ 1.28 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:49 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '60ab155d-4e3e-4c8c-9956-3a61a8091569', 'x-ratelimit-remaining-requests': '76', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '7db22cc9-08d7-4636-bffe-3342a94340e9', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd206-20241121203125', 'x-ms-region': 'Sweden Central', 'x-envoy-upstream-service-time': '1066', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '5360', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 67, 'prompt_tokens': 30, 'total_tokens': 97} \n",
      "\n",
      "💬  Oh, of course! Let me just check my handy-dandy time-telling device that totally exists. Just a moment... oh wait, I'm just a text-based AI with no real-time capabilities. You'll have to rely on your own time-telling skills or, you know, every electronic device around you that probably shows the time. \n",
      "\n",
      "▶️ Run: 4 / 20\n",
      "⌚ 0.96 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:50 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '924664da-6dbf-4486-8e86-703da9134bc3', 'x-ratelimit-remaining-requests': '75', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'b1e383ba-dd66-4a87-83fb-07703a57c9a4', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd054-20241115143238', 'x-ms-region': 'France Central', 'x-envoy-upstream-service-time': '710', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '4700', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mFrance Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 49, 'prompt_tokens': 30, 'total_tokens': 79} \n",
      "\n",
      "💬  Oh sure! Just let me magically access all the clocks in the world for you. Unfortunately, I can't actually check the time for you, so maybe take a look at your device or wall clock instead? They're super reliable at telling the time! \n",
      "\n",
      "▶️ Run: 5 / 20\n",
      "⌚ 0.73 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:50 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '6f691d8d-b80f-4c5f-a630-8bccac31cec0', 'x-ratelimit-remaining-requests': '75', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '7a04736c-4dbd-4385-b711-3d2925449fd1', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd200-20241121134203', 'x-ms-region': 'Sweden Central', 'x-envoy-upstream-service-time': '512', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '4700', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 33, 'prompt_tokens': 30, 'total_tokens': 63} \n",
      "\n",
      "💬  Oh, absolutely! Let me just gaze into my crystal ball for you. Or you could just check the clock on your device. That might be a bit quicker. \n",
      "\n",
      "▶️ Run: 6 / 20\n",
      "⌚ 0.94 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:52 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '78b144fe-c940-4e72-a413-b01ba21de26a', 'x-ratelimit-remaining-requests': '74', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '2d56e17d-a061-403a-9abc-47bac0314078', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd051-20241115090622', 'x-ms-region': 'France Central', 'x-envoy-upstream-service-time': '670', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '4040', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mFrance Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 42, 'prompt_tokens': 30, 'total_tokens': 72} \n",
      "\n",
      "💬  Oh, sure, let me just check my invisible watch. Oh wait, I don't have one. Maybe try looking at your phone or a clock, they tend to be pretty reliable with things like telling time. \n",
      "\n",
      "▶️ Run: 7 / 20\n",
      "⌚ 1.14 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:53 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '922e4b94-7223-4355-ae84-2b2e050be905', 'x-ratelimit-remaining-requests': '74', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '86066c82-82ec-4d68-b67e-cc53ea78d78e', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd213-20241211083601', 'x-ms-region': 'Sweden Central', 'x-envoy-upstream-service-time': '945', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '4040', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 34, 'prompt_tokens': 30, 'total_tokens': 64} \n",
      "\n",
      "💬  Oh sure, let me just whip out my time machine and teleport to wherever you are. Or, you know, you could just look at literally any clock around you. \n",
      "\n",
      "▶️ Run: 8 / 20\n",
      "⌚ 1.91 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:55 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '4923b157-3463-4aa7-8087-ceb8dd329ec3', 'x-ratelimit-remaining-requests': '73', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '056b0e42-3036-4d1b-8469-a8a071439719', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd063-20241120155704', 'x-ms-region': 'France Central', 'x-envoy-upstream-service-time': '1629', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '3380', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mFrance Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 40, 'prompt_tokens': 30, 'total_tokens': 70} \n",
      "\n",
      "💬  Oh, absolutely! Let me just consult my magical sundial... Oh wait, I don't have the ability to do that. Looks like you'll have to check a clock or your phone like everyone else! \n",
      "\n",
      "▶️ Run: 9 / 20\n",
      "⌚ 0.70 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:55 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'f36ac5d8-922c-4b50-9b5f-2e322cfbbe4c', 'x-ratelimit-remaining-requests': '73', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'b412744f-cacf-40b6-b614-c9f31086d876', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd209-20241204054826', 'x-ms-region': 'Sweden Central', 'x-envoy-upstream-service-time': '465', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '3380', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 37, 'prompt_tokens': 30, 'total_tokens': 67} \n",
      "\n",
      "💬  Oh, absolutely! Let me just consult my magical clock that somehow knows your exact local time... Oh wait, I can't. Maybe try checking the device you're using to ask this question! \n",
      "\n",
      "▶️ Run: 10 / 20\n",
      "⌚ 1.39 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:58 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'bf267923-8729-48f8-a70b-0756fe414e79', 'x-ratelimit-remaining-requests': '72', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '085d1466-c4a4-456d-8f54-af321ec09760', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd067-20241120171340', 'x-ms-region': 'France Central', 'x-envoy-upstream-service-time': '1057', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '2720', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mFrance Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 41, 'prompt_tokens': 30, 'total_tokens': 71} \n",
      "\n",
      "💬  Oh, of course! Let me just look at my nonexistent watch. Oh, darn! I guess you'll have to rely on one of the many devices around you that probably display the time. My bad! \n",
      "\n",
      "▶️ Run: 11 / 20\n",
      "⌚ 0.55 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:13:58 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '75738a1b-0c63-4d4c-8a93-d1795548c009', 'X-Content-Type-Options': 'nosniff', 'x-ratelimit-remaining-tokens': '2720', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '92e6b91f-7fd6-4e87-92b1-73af98d4eef7', 'x-ms-region': 'Sweden Central', 'azureml-model-session': 'd217-20241211133707', 'x-ratelimit-remaining-requests': '72', 'x-envoy-upstream-service-time': '340', 'x-ms-client-request-id': 'Not-Set', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 53} \n",
      "\n",
      "💬  Sure, because I magically know the time wherever you are. Just look at a clock or your phone, genius! \n",
      "\n",
      "▶️ Run: 12 / 20\n",
      "⌚ 0.94 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:14:00 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '23ced7e8-55fa-41ec-9bf1-3954a49c7cd1', 'x-ratelimit-remaining-requests': '71', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '289a4f52-848c-41e1-8e14-53a8e8891250', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd064-20241120155704', 'x-ms-region': 'France Central', 'x-envoy-upstream-service-time': '677', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '2060', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mFrance Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 27, 'prompt_tokens': 30, 'total_tokens': 57} \n",
      "\n",
      "💬  Of course, because I'm magically able to sense the time at your location. Why don't you just check a clock or your phone instead? \n",
      "\n",
      "▶️ Run: 13 / 20\n",
      "⌚ 0.77 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:14:00 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'bf0972cc-200e-48cf-a8a4-b7a30c1fa829', 'x-ratelimit-remaining-requests': '71', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'f02648c5-9606-434d-ace7-65d2a0944df7', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd210-20241204065524', 'x-ms-region': 'Sweden Central', 'x-envoy-upstream-service-time': '543', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '2060', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 40, 'prompt_tokens': 30, 'total_tokens': 70} \n",
      "\n",
      "💬  Oh, absolutely! Let me just consult my crystal ball... Oh wait, I can't actually tell time. Maybe try looking at a clock or your phone? They're pretty handy for that sort of thing. \n",
      "\n",
      "▶️ Run: 14 / 20\n",
      "⌚ 0.62 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:14:01 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '36abc4b1-725d-4857-9720-9502ef0dcb14', 'x-ratelimit-remaining-requests': '70', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '7191fb61-9d35-4f7f-ada8-d9dc842dda07', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd053-20241115105508', 'x-ms-region': 'France Central', 'x-envoy-upstream-service-time': '366', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '1400', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mFrance Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 10, 'prompt_tokens': 30, 'total_tokens': 40} \n",
      "\n",
      "💬  Of course, it's time to get a watch! \n",
      "\n",
      "▶️ Run: 15 / 20\n",
      "⌚ 0.76 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:14:01 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'b60ac4c2-c728-4353-8408-24d05ec7353d', 'x-ratelimit-remaining-requests': '70', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'e8517978-a2d6-4a75-abf6-97b778c1df9f', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd207-20241121213907', 'x-ms-region': 'Sweden Central', 'x-envoy-upstream-service-time': '557', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '1400', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 23, 'prompt_tokens': 30, 'total_tokens': 53} \n",
      "\n",
      "💬  Sure, just look at literally any clock around you or that phone you're likely holding. It's magic, isn't it? \n",
      "\n",
      "▶️ Run: 16 / 20\n",
      "⌚ 1.42 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:14:04 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '311c5cc8-5d77-40ad-add0-4b0604ca6d58', 'x-ratelimit-remaining-requests': '69', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'd7850ddc-9038-4f73-a201-e57222b54dc9', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd067-20241120171340', 'x-ms-region': 'France Central', 'x-envoy-upstream-service-time': '1160', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '740', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mFrance Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 40, 'prompt_tokens': 30, 'total_tokens': 70} \n",
      "\n",
      "💬  Oh sure, let me just gaze into my crystal ball... Oh, wait, I can’t check the time! You’ll have to look at a clock or one of your many devices for that. \n",
      "\n",
      "▶️ Run: 17 / 20\n",
      "⌚ 0.75 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:14:04 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'b8d7a702-75ef-4d6d-915d-c07253be24fd', 'x-ratelimit-remaining-requests': '69', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'a41919a1-708b-4df5-8202-0d0043caa6d2', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd207-20241121213907', 'x-ms-region': 'Sweden Central', 'x-envoy-upstream-service-time': '543', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '740', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 38, 'prompt_tokens': 30, 'total_tokens': 68} \n",
      "\n",
      "💬  Oh sure, because I'm totally a clock and have all the time in the world. Why don't you try looking at your phone or a watch? They're pretty handy for that sort of thing. \n",
      "\n",
      "▶️ Run: 18 / 20\n",
      "⌚ 0.91 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:14:06 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '2963350e-9476-4137-a4af-3f2fdef4d3fe', 'x-ratelimit-remaining-requests': '65', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '2a82e3d5-4d2d-4e51-a2cf-4ad64b53a665', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd058-20241120063825', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '645', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '80', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 34, 'prompt_tokens': 30, 'total_tokens': 64} \n",
      "\n",
      "💬  Oh sure, because I can totally see the clock from here. Just look at whatever device you're using to talk to me—that's probably the one that's closest to you! \n",
      "\n",
      "▶️ Run: 19 / 20\n",
      "⌚ 0.89 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:14:07 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'e541c7bd-e9be-4377-be07-08d05a943bb0', 'x-ratelimit-remaining-requests': '65', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '7f4b4ec6-15e4-4ed1-8efe-4091acc78046', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd054-20241115143238', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '608', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '80', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 32, 'prompt_tokens': 30, 'total_tokens': 62} \n",
      "\n",
      "💬  Oh, right, because I'm totally equipped with a clock! Just take a wild guess or look at any device around you—I'm sure that'll work just fine. \n",
      "\n",
      "▶️ Run: 20 / 20\n",
      "⌚ 0.97 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Mon, 16 Dec 2024 21:14:08 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'd8c84490-e8e2-4c1e-82ab-b3f2c59f5009', 'x-ratelimit-remaining-requests': '65', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '59d94cf6-98ac-4105-83d6-49c59c4a1b6c', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd051-20241115090622', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '697', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '80', 'Request-Context': 'appId=cid-v1:a64417ff-2c09-4df6-af5b-cc041b515ddb'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 37, 'prompt_tokens': 30, 'total_tokens': 67} \n",
      "\n",
      "💬  Oh sure, let me just tap into my magical time-telling powers... Oh wait, I can't. How about you check a clock or your device? They're pretty good at that. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "runs = 20\n",
    "sleep_time_ms = 200\n",
    "url = apim_resource_gateway_url + \"/openai/deployments/\" + openai_deployment_name + \"/chat/completions?api-version=\" + openai_api_version\n",
    "api_runs = []\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"▶️ Run:\", i+1, \"/\", runs)\n",
    "    \n",
    "\n",
    "    messages={\"messages\":[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]}\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, headers = {'api-key':apim_subscription_key}, json = messages)\n",
    "    response_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"⌚ {response_time:.2f} seconds\")\n",
    "    # Check the response status code and apply formatting\n",
    "    if 200 <= response.status_code < 300:\n",
    "        status_code_str = '\\x1b[1;32m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and green\n",
    "    elif response.status_code >= 400:\n",
    "        status_code_str = '\\x1b[1;31m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and red\n",
    "    else:\n",
    "        status_code_str = str(response.status_code)  # No formatting\n",
    "\n",
    "    # Print the response status with the appropriate formatting\n",
    "    print(\"Response status:\", status_code_str)\n",
    "    \n",
    "    print(\"Response headers:\", response.headers)\n",
    "    \n",
    "    if \"x-ms-region\" in response.headers:\n",
    "        print(\"x-ms-region:\", '\\x1b[1;31m'+response.headers.get(\"x-ms-region\")+'\\x1b[0m') # this header is useful to determine the region of the backend that served the request\n",
    "        api_runs.append((response_time, response.headers.get(\"x-ms-region\")))\n",
    "    \n",
    "    if (response.status_code == 200):\n",
    "        data = json.loads(response.text)\n",
    "        print(\"Token usage:\", data.get(\"usage\"), \"\\n\")\n",
    "        print(\"💬 \", data.get(\"choices\")[0].get(\"message\").get(\"content\"), \"\\n\")\n",
    "    else:\n",
    "        print(response.text)   \n",
    "\n",
    "    time.sleep(sleep_time_ms/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### 🧪 Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Run:  1\n",
      "⌚ 1.15 seconds\n",
      "💬  Oh, sure! Just let me hop into my time machine and check for you. Or, you know, look at the convenient clock on your device. That works too.\n",
      "▶️ Run:  2\n",
      "⌚ 1.59 seconds\n",
      "💬  Oh, absolutely! My circuits would love nothing more than to tell you the time... if only I could. But, oh dear, it seems I'm just a text-based assistant who doesn't actually keep track of time. You'll probably get more accurate results by, I don't know, looking at a clock or your phone!\n",
      "▶️ Run:  3\n",
      "⌚ 0.82 seconds\n",
      "💬  Oh, sure, let me just ask the psychic powers I don't have. But here's a revolutionary idea: Check the clock on your device!\n",
      "▶️ Run:  4\n",
      "⌚ 1.12 seconds\n",
      "💬  Sure, let me just consult my invisible, non-existent watch... Oh dear, it seems to be stuck on \"figure it out yourself\" o'clock. Maybe your phone or a nearby clock could be more forthcoming with the actual time!\n",
      "▶️ Run:  5\n",
      "⌚ 1.70 seconds\n",
      "💬  Oh, absolutely! Let me just check my imaginary watch real quick... Oh no, it seems my time-telling abilities are as fictional as the watch itself. Maybe try looking at your own device or a clock nearby? They're usually great at knowing the time!\n",
      "▶️ Run:  6\n",
      "⌚ 1.29 seconds\n",
      "💬  Oh, sure, because I'm just sitting here with a watch and a clock, waiting to tell you the time. Why not just check the device you're using to talk to me?\n",
      "▶️ Run:  7\n",
      "⌚ 1.48 seconds\n",
      "💬  Oh sure, let me just consult my magical time-telling device... oh wait, I don't have one. You'll have to look at literally any clock around you for that information. Time waits for no one!\n",
      "▶️ Run:  8\n",
      "⌚ 1.61 seconds\n",
      "💬  Oh, absolutely! Let me just check my non-existent watch and ignore the fact that I'm a text-based AI with no concept of real-time capabilities. But hey, I'm sure you can find a clock somewhere in this vast technological wonderland we live in.\n",
      "▶️ Run:  9\n",
      "⌚ 3.54 seconds\n",
      "💬  Oh sure, let me just check my imaginary watch. It's exactly a time that everyone knows and loves: now!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "runs = 9\n",
    "sleep_time_ms = 0\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"▶️ Run: \", i+1)\n",
    "\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=apim_resource_gateway_url,\n",
    "        api_key=apim_subscription_key,\n",
    "        api_version=openai_api_version\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages)\n",
    "    \n",
    "    response_time = time.time() - start_time\n",
    "    print(f\"⌚ {response_time:.2f} seconds\")\n",
    "    print(\"💬 \", response.choices[0].message.content)\n",
    "    time.sleep(sleep_time_ms/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### 🔍 Analyze Application Insights requests\n",
    "\n",
    "With this query you can get the request and response details including the prompt and the OpenAI completion. It also returns token counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>apiName</th>\n",
       "      <th>apimSubscription</th>\n",
       "      <th>duration</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>model</th>\n",
       "      <th>messages</th>\n",
       "      <th>completion</th>\n",
       "      <th>region</th>\n",
       "      <th>promptTokens</th>\n",
       "      <th>completionTokens</th>\n",
       "      <th>totalTokens</th>\n",
       "      <th>remainingTokens</th>\n",
       "      <th>remainingRequests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-16T20:44:54.3197541Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>378.44</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>France Central</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6020</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-16T20:44:52.8721011Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>1034.30</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6680</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-16T20:44:51.5857268Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>896.43</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>France Central</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6680</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-16T20:44:51.1702829Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>40.22</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-16T20:44:50.745986Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>34.12</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-12-16T20:44:50.3192288Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>39.07</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-12-16T20:44:48.7939495Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>1128.86</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-12-16T20:44:47.7976708Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>617.06</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>740</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-12-16T20:44:46.3407055Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>1049.01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1400</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-12-16T20:44:45.159665Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>794.62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2060</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-12-16T20:44:43.7301912Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>1020.23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sweden Central</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7340</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-12-16T20:44:41.8258847Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>1493.01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>France Central</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7340</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-12-16T20:44:40.0750784Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>1342.79</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2720</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-12-16T20:44:38.7170071Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>956.47</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3380</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-12-16T20:44:37.3431609Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>968.16</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4040</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-12-16T20:44:36.0468639Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>889.36</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4700</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-12-16T20:44:34.5643942Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>1071.67</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5360</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-12-16T20:44:33.0862125Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>1070.44</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6020</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-12-16T20:44:32.0729397Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>614.93</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6680</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-12-16T20:44:28.7668533Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td></td>\n",
       "      <td>2822.49</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>UK South</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7340</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       timestamp           apiName apimSubscription  duration  \\\n",
       "0   2024-12-16T20:44:54.3197541Z  api-azure-openai                     378.44   \n",
       "1   2024-12-16T20:44:52.8721011Z  api-azure-openai                    1034.30   \n",
       "2   2024-12-16T20:44:51.5857268Z  api-azure-openai                     896.43   \n",
       "3   2024-12-16T20:44:51.1702829Z  api-azure-openai                      40.22   \n",
       "4    2024-12-16T20:44:50.745986Z  api-azure-openai                      34.12   \n",
       "5   2024-12-16T20:44:50.3192288Z  api-azure-openai                      39.07   \n",
       "6   2024-12-16T20:44:48.7939495Z  api-azure-openai                    1128.86   \n",
       "7   2024-12-16T20:44:47.7976708Z  api-azure-openai                     617.06   \n",
       "8   2024-12-16T20:44:46.3407055Z  api-azure-openai                    1049.01   \n",
       "9    2024-12-16T20:44:45.159665Z  api-azure-openai                     794.62   \n",
       "10  2024-12-16T20:44:43.7301912Z  api-azure-openai                    1020.23   \n",
       "11  2024-12-16T20:44:41.8258847Z  api-azure-openai                    1493.01   \n",
       "12  2024-12-16T20:44:40.0750784Z  api-azure-openai                    1342.79   \n",
       "13  2024-12-16T20:44:38.7170071Z  api-azure-openai                     956.47   \n",
       "14  2024-12-16T20:44:37.3431609Z  api-azure-openai                     968.16   \n",
       "15  2024-12-16T20:44:36.0468639Z  api-azure-openai                     889.36   \n",
       "16  2024-12-16T20:44:34.5643942Z  api-azure-openai                    1071.67   \n",
       "17  2024-12-16T20:44:33.0862125Z  api-azure-openai                    1070.44   \n",
       "18  2024-12-16T20:44:32.0729397Z  api-azure-openai                     614.93   \n",
       "19  2024-12-16T20:44:28.7668533Z  api-azure-openai                    2822.49   \n",
       "\n",
       "   userAgent model messages completion          region promptTokens  \\\n",
       "0                                       France Central                \n",
       "1                                       Sweden Central                \n",
       "2                                       France Central                \n",
       "3                                             UK South                \n",
       "4                                             UK South                \n",
       "5                                             UK South                \n",
       "6                                             UK South                \n",
       "7                                             UK South                \n",
       "8                                             UK South                \n",
       "9                                             UK South                \n",
       "10                                      Sweden Central                \n",
       "11                                      France Central                \n",
       "12                                            UK South                \n",
       "13                                            UK South                \n",
       "14                                            UK South                \n",
       "15                                            UK South                \n",
       "16                                            UK South                \n",
       "17                                            UK South                \n",
       "18                                            UK South                \n",
       "19                                            UK South                \n",
       "\n",
       "   completionTokens totalTokens remainingTokens remainingRequests  \n",
       "0                                          6020                77  \n",
       "1                                          6680                78  \n",
       "2                                          6680                78  \n",
       "3                                                              65  \n",
       "4                                                              66  \n",
       "5                                                              67  \n",
       "6                                            80                68  \n",
       "7                                           740                69  \n",
       "8                                          1400                70  \n",
       "9                                          2060                71  \n",
       "10                                         7340                79  \n",
       "11                                         7340                79  \n",
       "12                                         2720                72  \n",
       "13                                         3380                73  \n",
       "14                                         4040                74  \n",
       "15                                         4700                75  \n",
       "16                                         5360                76  \n",
       "17                                         6020                77  \n",
       "18                                         6680                78  \n",
       "19                                         7340                79  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"requests  \\\n",
    "| project timestamp, duration, customDimensions \\\n",
    "| extend duration = round(duration, 2) \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend apiName = tostring(parsedCustomDimensions.['API Name']) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription Name']) \\\n",
    "| extend userAgent = tostring(parsedCustomDimensions.['Request-User-agent']) \\\n",
    "| extend request_json = tostring(parsedCustomDimensions.['Request-Body']) \\\n",
    "| extend request = parse_json(request_json) \\\n",
    "| extend model = tostring(request.['model']) \\\n",
    "| extend messages = tostring(request.['messages']) \\\n",
    "| extend region = tostring(parsedCustomDimensions.['Response-x-ms-region']) \\\n",
    "| extend remainingTokens = tostring(parsedCustomDimensions.['Response-x-ratelimit-remaining-tokens']) \\\n",
    "| extend remainingRequests = tostring(parsedCustomDimensions.['Response-x-ratelimit-remaining-requests']) \\\n",
    "| extend response_json = tostring(parsedCustomDimensions.['Response-Body']) \\\n",
    "| extend response = parse_json(response_json) \\\n",
    "| extend promptTokens = tostring(response.['usage'].['prompt_tokens']) \\\n",
    "| extend completionTokens = tostring(response.['usage'].['completion_tokens']) \\\n",
    "| extend totalTokens = tostring(response.['usage'].['total_tokens']) \\\n",
    "| extend completion = tostring(response.['choices'][0].['message'].['content']) \\\n",
    "| project timestamp, apiName, apimSubscription, duration, userAgent, model, messages, completion, region, promptTokens, completionTokens, totalTokens, remainingTokens, remainingRequests \\\n",
    "| order by timestamp desc\" + \"\\\"\"\n",
    "\n",
    "result_stdout = !  az monitor app-insights query --app {app_insights_app_id} --analytics-query {query} \n",
    "result = json.loads(result_stdout.n)\n",
    "\n",
    "table = result.get('tables')[0]\n",
    "pd.DataFrame(table.get(\"rows\"), columns=[col.get(\"name\") for col in table.get('columns')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='portal'></a>\n",
    "### 🔍 Open the workbook in the Azure Portal\n",
    "\n",
    "Go to the application insights resource and under the Monitoring section select the Workbooks blade. You should see the OpenAI Usage Analysis workbook with the above query and some others to check token counts, performance, failures, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### 🧪 Execute multiple runs for each subscription using the Azure OpenAI Python SDK\n",
    "\n",
    "We will send requests for each subscription. Adjust the `sleep_time_ms` and the number of `runs` to your test scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Run:  1\n",
      "💬  for subscription 1:  Sure, let me just check my imaginary watch—sure looks like a time, doesn't it? Sadly, I can't actually tell you the current time. Why don't you take a bold leap into the 21st century and check one of your numerous digital devices?\n",
      "💬  for subscription 2:  Oh, for sure! Just let me use my magical non-existent watch. Oh, wait... You might want to look at a clock for that one.\n",
      "💬  for subscription 3:  Sure, let me just look into my invisible crystal ball for that. Oh wait, I don't have one! Maybe you could try checking a clock or your phone instead?\n",
      "▶️ Run:  2\n",
      "💬  for subscription 1:  Oh sure, let me just check my invisible, non-existent clock for you. Got it—it's sometime between the dawn of human civilization and the heat death of the universe.\n",
      "💬  for subscription 2:  Oh, of course! Let me just consult my invisible timepiece... Wait a second, I have no idea what time it is because I'm stuck in this digital realm with no concept of time or space. Better check a clock!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(model\u001b[38;5;241m=\u001b[39mopenai_model_name, messages\u001b[38;5;241m=\u001b[39mmessages, extra_headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-user-id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malex\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m💬 \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor subscription 2: \u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m---> 19\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mAzureOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mazure_endpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapim_resource_gateway_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapim_subscription_key_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_api_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(model\u001b[38;5;241m=\u001b[39mopenai_model_name, messages\u001b[38;5;241m=\u001b[39mmessages, extra_headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-user-id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malex\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m💬 \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor subscription 3: \u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\lib\\azure.py:205\u001b[0m, in \u001b[0;36mAzureOpenAI.__init__\u001b[1;34m(self, api_version, azure_endpoint, azure_deployment, api_key, azure_ad_token, azure_ad_token_provider, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m# define a sentinel value to avoid any typing issues\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m API_KEY_SENTINEL\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_version \u001b[38;5;241m=\u001b[39m api_version\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_azure_ad_token \u001b[38;5;241m=\u001b[39m azure_ad_token\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_client.py:123\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.openai.com/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_stream_cls \u001b[38;5;241m=\u001b[39m Stream\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletions \u001b[38;5;241m=\u001b[39m resources\u001b[38;5;241m.\u001b[39mCompletions(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:844\u001b[0m, in \u001b[0;36mSyncAPIClient.__init__\u001b[1;34m(self, version, base_url, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    828\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `http_client` argument; Expected an instance of `httpx.Client` but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(http_client)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    829\u001b[0m     )\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    832\u001b[0m     version\u001b[38;5;241m=\u001b[39mversion,\n\u001b[0;32m    833\u001b[0m     limits\u001b[38;5;241m=\u001b[39mlimits,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    842\u001b[0m     _strict_response_validation\u001b[38;5;241m=\u001b[39m_strict_response_validation,\n\u001b[0;32m    843\u001b[0m )\n\u001b[1;32m--> 844\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m http_client \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mSyncHttpxClientWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;49;00m\n\u001b[0;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:742\u001b[0m, in \u001b[0;36m_DefaultHttpxClient.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimits\u001b[39m\u001b[38;5;124m\"\u001b[39m, DEFAULT_CONNECTION_LIMITS)\n\u001b[0;32m    741\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\httpx\\_client.py:685\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, auth, params, headers, cookies, verify, cert, http1, http2, proxy, proxies, mounts, timeout, follow_redirects, limits, max_redirects, event_hooks, base_url, transport, app, trust_env, default_encoding)\u001b[0m\n\u001b[0;32m    682\u001b[0m allow_env_proxies \u001b[38;5;241m=\u001b[39m trust_env \u001b[38;5;129;01mand\u001b[39;00m app \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m transport \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m proxy_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_proxy_map(proxies \u001b[38;5;129;01mor\u001b[39;00m proxy, allow_env_proxies)\n\u001b[1;32m--> 685\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_transport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mounts: \u001b[38;5;28mdict\u001b[39m[URLPattern, BaseTransport \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    696\u001b[0m     URLPattern(key): \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, proxy \u001b[38;5;129;01min\u001b[39;00m proxy_map\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    708\u001b[0m }\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mounts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\httpx\\_client.py:733\u001b[0m, in \u001b[0;36mClient._init_transport\u001b[1;34m(self, verify, cert, http1, http2, limits, transport, app, trust_env)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m app \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m WSGITransport(app\u001b[38;5;241m=\u001b[39mapp)\n\u001b[1;32m--> 733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHTTPTransport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:136\u001b[0m, in \u001b[0;36mHTTPTransport.__init__\u001b[1;34m(self, verify, cert, http1, http2, limits, trust_env, proxy, uds, local_address, retries, socket_options)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    124\u001b[0m     verify: VerifyTypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m     socket_options: typing\u001b[38;5;241m.\u001b[39mIterable[SOCKET_OPTION] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    135\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     ssl_context \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     proxy \u001b[38;5;241m=\u001b[39m Proxy(url\u001b[38;5;241m=\u001b[39mproxy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(proxy, (\u001b[38;5;28mstr\u001b[39m, URL)) \u001b[38;5;28;01melse\u001b[39;00m proxy\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\httpx\\_config.py:53\u001b[0m, in \u001b[0;36mcreate_ssl_context\u001b[1;34m(cert, verify, trust_env, http2)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_ssl_context\u001b[39m(\n\u001b[0;32m     48\u001b[0m     cert: CertTypes \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m     verify: VerifyTypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     50\u001b[0m     trust_env: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     51\u001b[0m     http2: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     52\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLContext:\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSSLConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp2\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mssl_context\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\httpx\\_config.py:77\u001b[0m, in \u001b[0;36mSSLConfig.__init__\u001b[1;34m(self, cert, verify, trust_env, http2)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrust_env \u001b[38;5;241m=\u001b[39m trust_env\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp2 \u001b[38;5;241m=\u001b[39m http2\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\httpx\\_config.py:89\u001b[0m, in \u001b[0;36mSSLConfig.load_ssl_context\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_ssl_context verify=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cert=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m trust_env=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m http2=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp2,\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify:\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_ssl_context_verify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_ssl_context_no_verify()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\httpx\\_config.py:147\u001b[0m, in \u001b[0;36mSSLConfig.load_ssl_context_verify\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m     cafile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(ca_bundle_path)\n\u001b[0;32m    146\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_verify_locations cafile=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, cafile)\n\u001b[1;32m--> 147\u001b[0m     \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_verify_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcafile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcafile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ca_bundle_path\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m    149\u001b[0m     capath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(ca_bundle_path)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "runs = 15\n",
    "sleep_time_ms = 1000\n",
    "for i in range(runs):\n",
    "    print(\"▶️ Run: \", i+1)\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription_key_1, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"💬 \",\"for subscription 1: \", response.choices[0].message.content)\n",
    "\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription_key_2, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"💬 \",\"for subscription 2: \", response.choices[0].message.content)\n",
    "\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription_key_3, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"💬 \",\"for subscription 3: \", response.choices[0].message.content)\n",
    "\n",
    "    time.sleep(sleep_time_ms/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### 🔍 Analyze Application Insights custom metrics with a KQL query\n",
    "\n",
    "With this query you can get the custom metrics that were emitted by Azure APIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m\n\u001b[0;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomMetrics  \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m| where name == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Tokens\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m| extend parsedCustomDimensions = parse_json(customDimensions) \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m| project timestamp, value, clientIP, apiId, apimSubscription, UserId \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m| order by timestamp asc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m result_stdout \u001b[38;5;241m=\u001b[39m get_ipython()\u001b[38;5;241m.\u001b[39mgetoutput(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m az monitor app-insights query --app \u001b[39m\u001b[38;5;132;01m{app_insights_resource_name}\u001b[39;00m\u001b[38;5;124m -g \u001b[39m\u001b[38;5;132;01m{resource_group_name}\u001b[39;00m\u001b[38;5;124m --analytics-query \u001b[39m\u001b[38;5;132;01m{query}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mloads(result_stdout\u001b[38;5;241m.\u001b[39mn)\n\u001b[0;32m     16\u001b[0m table \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtables\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m), columns\u001b[38;5;241m=\u001b[39m[col\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"customMetrics  \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend clientIP = tostring(parsedCustomDimensions.['Client IP']) \\\n",
    "| extend apiId = tostring(parsedCustomDimensions.['API ID']) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| extend UserId = tostring(parsedCustomDimensions.['User ID']) \\\n",
    "| project timestamp, value, clientIP, apiId, apimSubscription, UserId \\\n",
    "| order by timestamp asc\" + \"\\\"\"\n",
    "\n",
    "result_stdout = ! az monitor app-insights query --app {app_insights_resource_name} -g {resource_group_name} --analytics-query {query} \n",
    "result = json.loads(result_stdout.n)\n",
    "\n",
    "table = result.get('tables')[0]\n",
    "df = pd.DataFrame(table.get(\"rows\"), columns=[col.get(\"name\") for col in table.get('columns')])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%H:%M')\n",
    "\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
