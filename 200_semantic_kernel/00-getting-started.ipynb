{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Import Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: semantic-kernel in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (1.20.0)\n",
      "Requirement already satisfied: aiohttp~=3.8 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (3.10.5)\n",
      "Requirement already satisfied: cloudevents~=1.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (2.9.1)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (2.5.2)\n",
      "Requirement already satisfied: defusedxml~=0.7 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: azure-identity~=1.13 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\python312\\lib\\site-packages (from semantic-kernel) (1.26.4)\n",
      "Requirement already satisfied: openai~=1.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (1.41.0)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (0.19.4)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (1.30.0)\n",
      "Requirement already satisfied: prance~=23.6.21.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (23.6.21.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in c:\\python312\\lib\\site-packages (from semantic-kernel) (3.1.3)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp~=3.8->semantic-kernel) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp~=3.8->semantic-kernel) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp~=3.8->semantic-kernel) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.11.1)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in c:\\python312\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (1.30.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\python312\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (42.0.8)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.24.0 in c:\\python312\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (1.28.1)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in c:\\python312\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (1.1.0)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2~=3.1->semantic-kernel) (2.1.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai~=1.0->semantic-kernel) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python312\\lib\\site-packages (from openai~=1.0->semantic-kernel) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from openai~=1.0->semantic-kernel) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from openai~=1.0->semantic-kernel) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai~=1.0->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai~=1.0->semantic-kernel) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\python312\\lib\\site-packages (from openai~=1.0->semantic-kernel) (4.12.1)\n",
      "Requirement already satisfied: isodate in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.6.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: parse in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: werkzeug in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-api~=1.24->semantic-kernel) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-api~=1.24->semantic-kernel) (6.11.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-sdk~=1.24->semantic-kernel) (0.51b0)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from prance~=23.6.21.0->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from prance~=23.6.21.0->semantic-kernel) (0.18.10)\n",
      "Requirement already satisfied: requests>=2.25 in c:\\python312\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (2.32.3)\n",
      "Requirement already satisfied: six~=1.15 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from prance~=23.6.21.0->semantic-kernel) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from prance~=23.6.21.0->semantic-kernel) (24.0)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python312\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel) (2.23.3)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\python312\\lib\\site-packages (from pydantic-settings~=2.0->semantic-kernel) (1.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai~=1.0->semantic-kernel) (3.7)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\python312\\lib\\site-packages (from cryptography>=2.5->azure-identity~=1.13->semantic-kernel) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24->semantic-kernel) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.20.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.20.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.4)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\python312\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.24.0->azure-identity~=1.13->semantic-kernel) (2.8.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.6 in c:\\python312\\lib\\site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity~=1.13->semantic-kernel) (2.8.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (2.2.1)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from ruamel.yaml>=0.17.10->prance~=23.6.21.0->semantic-kernel) (0.2.12)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>4->openai~=1.0->semantic-kernel) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\python312\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity~=1.13->semantic-kernel) (2.22)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\hodellai\\appdata\\roaming\\python\\python312\\site-packages (from portalocker<3,>=1.6->msal-extensions<2.0.0,>=0.3.0->azure-identity~=1.13->semantic-kernel) (306)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.20.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: if using a virtual environment, do not run this cell\n",
    "%pip install -U semantic-kernel\n",
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial configuration for the notebook to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure paths are correct for the imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "sys.path.append(grandparent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the Kernel\n",
    "\n",
    "Let's get started with the necessary configuration to run Semantic Kernel. For Notebooks, we require a `.env` file with the proper settings for the model you use. Create a new file named `.env` and place it in this directory. Copy the contents of the `.env.example` file from this directory and paste it into the `.env` file that you just created.\n",
    "\n",
    "**NOTE: Please make sure to include `GLOBAL_LLM_SERVICE` set to either OpenAI, AzureOpenAI, or HuggingFace in your .env file. If this setting is not included, the Service will default to AzureOpenAI.**\n",
    "\n",
    "#### Using Azure OpenAI\n",
    "\n",
    "Add your [Azure Open AI Service key](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio) settings to the `.env` file in the same folder:\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"AzureOpenAI\"\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_TEXT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_API_VERSION=\"...\"\n",
    "```\n",
    "The names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "For more advanced configuration, please follow the steps outlined in the [setup guide](./CONFIGURING_THE_KERNEL.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our kernel for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now configure our Chat Completion service on the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all services so that this cell can be re-run without restarting the kernel\n",
    "kernel.remove_all_services()\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"default\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a Semantic Function\n",
    "\n",
    "**Step 3**: Load a Plugin and run a semantic function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugin = kernel.add_plugin(parent_directory=\"./\", plugin_name=\"FunPlugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function failed. Error: Error occurred while invoking function Joke: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", NotFoundError(\"Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\"))\n",
      "Something went wrong in function invocation. During function invocation: 'FunPlugin-Joke'. Error description: 'Error occurred while invoking function Joke: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", NotFoundError(\"Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\"))'\n"
     ]
    },
    {
     "ename": "KernelInvokeException",
     "evalue": "Error occurred while invoking function: 'FunPlugin-Joke'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:87\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     86\u001b[0m         settings_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 87\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings_dict)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\resources\\chat\\completions.py:1339\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1338\u001b[0m validate_response_format(response_format)\n\u001b[1;32m-> 1339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1341\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[0;32m   1342\u001b[0m         {\n\u001b[0;32m   1343\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1344\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1345\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1346\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1347\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1349\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1350\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1351\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1352\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1353\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1354\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1355\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1356\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1357\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1358\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1359\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1360\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1361\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1362\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1363\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1364\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1365\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1366\u001b[0m         },\n\u001b[0;32m   1367\u001b[0m         completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m   1368\u001b[0m     ),\n\u001b[0;32m   1369\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1370\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1371\u001b[0m     ),\n\u001b[0;32m   1372\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1373\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1374\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[0;32m   1375\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:1816\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1813\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1814\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1815\u001b[0m )\n\u001b[1;32m-> 1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:1510\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1503\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1508\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1511\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1512\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1513\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1514\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1515\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m   1516\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_base_client.py:1611\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1610\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1614\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1615\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1620\u001b[0m )\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceResponseException\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\functions\\kernel_function_from_prompt.py:174\u001b[0m, in \u001b[0;36mKernelFunctionFromPrompt._invoke_internal\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     chat_message_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m prompt_render_result\u001b[38;5;241m.\u001b[39mai_service\u001b[38;5;241m.\u001b[39mget_chat_message_contents(\n\u001b[0;32m    175\u001b[0m         chat_history\u001b[38;5;241m=\u001b[39mchat_history,\n\u001b[0;32m    176\u001b[0m         settings\u001b[38;5;241m=\u001b[39mprompt_render_result\u001b[38;5;241m.\u001b[39mexecution_settings,\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\u001b[38;5;241m.\u001b[39mkernel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\u001b[38;5;241m.\u001b[39marguments},\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\connectors\\ai\\chat_completion_client_base.py:134\u001b[0m, in \u001b[0;36mChatCompletionClientBase.get_chat_message_contents\u001b[1;34m(self, chat_history, settings, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    131\u001b[0m     settings\u001b[38;5;241m.\u001b[39mfunction_choice_behavior \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mfunction_choice_behavior\u001b[38;5;241m.\u001b[39mauto_invoke_kernel_functions\n\u001b[0;32m    133\u001b[0m ):\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_get_chat_message_contents(chat_history, settings)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Auto invoke loop\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\utils\\telemetry\\model_diagnostics\\decorators.py:111\u001b[0m, in \u001b[0;36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    113\u001b[0m completion_service: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionClientBase\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_chat_completion_base.py:88\u001b[0m, in \u001b[0;36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[1;34m(self, chat_history, settings)\u001b[0m\n\u001b[0;32m     86\u001b[0m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_id\n\u001b[1;32m---> 88\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(settings)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:59\u001b[0m, in \u001b[0;36mOpenAIHandler._send_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_completion_request(settings)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_type \u001b[38;5;241m==\u001b[39m OpenAIModelTypes\u001b[38;5;241m.\u001b[39mEMBEDDING:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:104\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to complete the prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    106\u001b[0m         ex,\n\u001b[0;32m    107\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;31mServiceResponseException\u001b[0m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", NotFoundError(\"Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\"))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFunctionExecutionException\u001b[0m                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\kernel.py:196\u001b[0m, in \u001b[0;36mKernel.invoke\u001b[1;34m(self, function, arguments, function_name, plugin_name, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m function\u001b[38;5;241m.\u001b[39minvoke(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, arguments\u001b[38;5;241m=\u001b[39marguments, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationCancelledException \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\functions\\kernel_function.py:256\u001b[0m, in \u001b[0;36mKernelFunction.invoke\u001b[1;34m(self, kernel, arguments, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(current_span, e, attributes)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\functions\\kernel_function.py:248\u001b[0m, in \u001b[0;36mKernelFunction.invoke\u001b[1;34m(self, kernel, arguments, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m stack \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mconstruct_call_stack(\n\u001b[0;32m    245\u001b[0m     filter_type\u001b[38;5;241m=\u001b[39mFilterTypes\u001b[38;5;241m.\u001b[39mFUNCTION_INVOCATION,\n\u001b[0;32m    246\u001b[0m     inner_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_internal,\n\u001b[0;32m    247\u001b[0m )\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m stack(function_context)\n\u001b[0;32m    250\u001b[0m KernelFunctionLogMessages\u001b[38;5;241m.\u001b[39mlog_function_invoked_success(logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfully_qualified_name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\functions\\kernel_function_from_prompt.py:180\u001b[0m, in \u001b[0;36mKernelFunctionFromPrompt._invoke_internal\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FunctionExecutionException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred while invoking function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_message_contents:\n",
      "\u001b[1;31mFunctionExecutionException\u001b[0m: Error occurred while invoking function Joke: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", NotFoundError(\"Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\"))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKernelInvokeException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msemantic_kernel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelArguments\n\u001b[0;32m      3\u001b[0m joke_function \u001b[38;5;241m=\u001b[39m plugin[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoke\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m joke \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m kernel\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m      6\u001b[0m     joke_function,\n\u001b[0;32m      7\u001b[0m     KernelArguments(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime travel to dinosaur age\u001b[39m\u001b[38;5;124m\"\u001b[39m, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuper silly\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(joke)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\kernel.py:205\u001b[0m, in \u001b[0;36mKernel.invoke\u001b[1;34m(self, function, arguments, function_name, plugin_name, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    201\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSomething went wrong in function invocation. During function invocation:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39mfully_qualified_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Error description: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m KernelInvokeException(\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred while invoking function: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39mfully_qualified_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    207\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mKernelInvokeException\u001b[0m: Error occurred while invoking function: 'FunPlugin-Joke'"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "joke_function = plugin[\"Joke\"]\n",
    "\n",
    "joke = await kernel.invoke(\n",
    "    joke_function,\n",
    "    KernelArguments(input=\"time travel to dinosaur age\", style=\"super silly\"),\n",
    ")\n",
    "print(joke)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
