{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Backend pool Load Balancing lab\n",
    "![flow](images/backend-pool-load-balancing.gif)\n",
    "\n",
    "Playground to try the built-in load balancing [backend pool functionality of APIM](https://learn.microsoft.com/en-us/azure/api-management/backends?tabs=bicep) to either a list of Azure OpenAI endpoints or mock servers.\n",
    "\n",
    "Notes:\n",
    "- The backend pool uses round-robin by default\n",
    "- But priority and weight based routing are also supported: Adjust the `priority` (the lower the number, the higher the priority) and `weight` parameters in the `openai_resources` variable\n",
    "- The `retry` API Management policy initiates a retry to an available backend if an HTTP 429 status code is encountered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using Terraform\n",
    "\n",
    "This lab uses Terraform to declaratively define all the resources that will be deployed. Change the [variables.tf](variables.tf) directly to try different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! terraform init\n",
    "! terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâüèª APIM Resource Gateway URL:  https://apim-genai-320-03.azure-api.net\n",
      "üëâüèª Application Insights App ID:  09361747-7755-43ae-af86-c2327d97eef2\n",
      "üëâüèª APIM Subscription Key 1:  8b755e4d29bd4270a25f89c785d671db\n",
      "üëâüèª APIM Subscription Key 2:  e1a68a747743473f98e2593fb8692ca1\n",
      "üëâüèª APIM Subscription Key 3:  b91719ba1575486e9a74f0d177d905f3\n",
      "üëâüèª Resource Group Name:  rg-apim-genai-320-03\n",
      "üëâüèª Application Insights Resource Name:  app-insights\n"
     ]
    }
   ],
   "source": [
    "apim_resource_gateway_url = ! terraform output -raw apim_resource_gateway_url\n",
    "apim_resource_gateway_url = apim_resource_gateway_url.n\n",
    "print(\"üëâüèª APIM Resource Gateway URL: \", apim_resource_gateway_url)\n",
    "\n",
    "app_insights_app_id = ! terraform output -raw app_insights_app_id\n",
    "app_insights_app_id = app_insights_app_id.n\n",
    "print(\"üëâüèª Application Insights App ID: \", app_insights_app_id)\n",
    "\n",
    "apim_subscription_key_1 = ! terraform output -raw apim_subscription_key_1\n",
    "apim_subscription_key_1 = apim_subscription_key_1.n\n",
    "print(\"üëâüèª APIM Subscription Key 1: \", apim_subscription_key_1)\n",
    "\n",
    "apim_subscription_key_2 = ! terraform output -raw apim_subscription_key_2\n",
    "apim_subscription_key_2 = apim_subscription_key_2.n\n",
    "print(\"üëâüèª APIM Subscription Key 2: \", apim_subscription_key_2)\n",
    "\n",
    "apim_subscription_key_3 = ! terraform output -raw apim_subscription_key_3\n",
    "apim_subscription_key_3 = apim_subscription_key_3.n\n",
    "print(\"üëâüèª APIM Subscription Key 3: \", apim_subscription_key_3)\n",
    "\n",
    "resource_group_name = ! terraform output -raw resource_group_name\n",
    "resource_group_name = resource_group_name.n\n",
    "print(\"üëâüèª Resource Group Name: \", resource_group_name)\n",
    "\n",
    "app_insights_resource_name = ! terraform output -raw app_insights_resource_name\n",
    "app_insights_resource_name = app_insights_resource_name.n\n",
    "print(\"üëâüèª Application Insights Resource Name: \", app_insights_resource_name)\n",
    "\n",
    "openai_api_version = \"2024-10-21\"\n",
    "openai_model_name = \"gpt-4o\"\n",
    "openai_deployment_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Important note about API Management Subscriptions\n",
    "\n",
    "You will need to go to the API Management instance in the Azure portal and click each one of the three subscriptions and save them to activate them. There might be a bug preventing subscriptions to be validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses. \n",
    "\n",
    "You will not see HTTP 429s returned as API Management's `retry` policy will select an available backend. If no backends are viable, an HTTP 503 will be returned.\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior of the backend pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Run: 1 / 10\n",
      "‚åö 2.62 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Fri, 20 Dec 2024 08:08:33 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '75995a02-4e94-474c-b56e-c046b5ccce6c', 'x-ratelimit-remaining-requests': '79', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '736955af-e43d-4a84-a3a2-806708fa5be0', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd029-20241114135521', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '903', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '7340', 'Request-Context': 'appId=cid-v1:09361747-7755-43ae-af86-c2327d97eef2'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 39, 'prompt_tokens': 30, 'total_tokens': 69} \n",
      "\n",
      "üí¨  Oh, absolutely! Let me teleport myself to wherever you are and glance at a clock. Or, you know, you could just check the device you're using right now. That might work too! \n",
      "\n",
      "‚ñ∂Ô∏è Run: 2 / 10\n",
      "‚åö 1.91 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Fri, 20 Dec 2024 08:08:35 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'd25a6e1b-8ad7-4801-b16b-d045aa193a88', 'x-ratelimit-remaining-requests': '78', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '2725e2ea-987f-4e2f-b3fa-e65c1ea9166b', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd055-20241120015010', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '1607', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '6680', 'Request-Context': 'appId=cid-v1:09361747-7755-43ae-af86-c2327d97eef2'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 48, 'prompt_tokens': 30, 'total_tokens': 78} \n",
      "\n",
      "üí¨  Oh, absolutely! I can totally see through the screen and magically know what time it is wherever you are. But since I'm just a text-based assistant, perhaps a quick glance at your device or a nearby clock might be slightly more effective. \n",
      "\n",
      "‚ñ∂Ô∏è Run: 3 / 10\n",
      "‚åö 1.02 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Fri, 20 Dec 2024 08:08:36 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '9fc96052-9c18-4011-83dc-58862d3cd04e', 'x-ratelimit-remaining-requests': '77', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'af4f8a2b-5132-4b09-aca0-a272e09f667d', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd013-20241125235722', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '751', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '6020', 'Request-Context': 'appId=cid-v1:09361747-7755-43ae-af86-c2327d97eef2'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 47, 'prompt_tokens': 30, 'total_tokens': 77} \n",
      "\n",
      "üí¨  Oh sure, let me just consult my magical crystal ball. Oops, it‚Äôs as clear as ever! Why not try checking a clock, your phone, or maybe the sun, like they used to in the olden days? \n",
      "\n",
      "‚ñ∂Ô∏è Run: 4 / 10\n",
      "‚åö 1.59 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Fri, 20 Dec 2024 08:08:38 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '09ece8c5-93cd-4d5d-979d-bb16407e6a33', 'x-ratelimit-remaining-requests': '76', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'b4cb52bd-29b7-4f36-afad-0623b8be475c', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd023-20241113101809', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '1241', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '5360', 'Request-Context': 'appId=cid-v1:09361747-7755-43ae-af86-c2327d97eef2'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 47, 'prompt_tokens': 30, 'total_tokens': 77} \n",
      "\n",
      "üí¨  Oh sure, let me just check my nonexistent watch. How about this: it's probably either too early or too late for something you should be doing. Try looking at one of those handy clocks or devices that people usually have on them. \n",
      "\n",
      "‚ñ∂Ô∏è Run: 5 / 10\n",
      "‚åö 1.21 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Fri, 20 Dec 2024 08:08:39 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '274352cc-5b9d-4ac3-8ceb-86789e85935b', 'x-ratelimit-remaining-requests': '75', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '96701f51-7a6f-4012-bea2-bb8758f67a9d', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd031-20241114182115', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '945', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '4700', 'Request-Context': 'appId=cid-v1:09361747-7755-43ae-af86-c2327d97eef2'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 49, 'prompt_tokens': 30, 'total_tokens': 79} \n",
      "\n",
      "üí¨  Oh sure, because I'm totally a clock. Just hold your wrist up to me and I'll magically transform into a Rolex. Or, you know, you could just check your phone or any other time-telling device that's probably within arm's reach. \n",
      "\n",
      "‚ñ∂Ô∏è Run: 6 / 10\n",
      "‚åö 1.29 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Fri, 20 Dec 2024 08:08:40 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'f86442e2-1ad3-42aa-8fe6-06cb8e25d0a6', 'x-ratelimit-remaining-requests': '74', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '1f579367-5759-4553-96ad-ebc7e906e0cc', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd025-20241113134504', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '1009', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '4040', 'Request-Context': 'appId=cid-v1:09361747-7755-43ae-af86-c2327d97eef2'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 38, 'prompt_tokens': 30, 'total_tokens': 68} \n",
      "\n",
      "üí¨  Oh sure, let me just check my invisible watch. Or, you know, you could just glance at literally any clock around you or your phone. They're usually pretty good at keeping time! \n",
      "\n",
      "‚ñ∂Ô∏è Run: 7 / 10\n",
      "‚åö 1.04 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Fri, 20 Dec 2024 08:08:41 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'a41775f6-2599-4476-a174-0f06440ef37d', 'x-ratelimit-remaining-requests': '73', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'a88b2a1d-1be9-4d1d-ac2d-b7a2f5845931', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd031-20241114182115', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '766', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '3380', 'Request-Context': 'appId=cid-v1:09361747-7755-43ae-af86-c2327d97eef2'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 37, 'prompt_tokens': 30, 'total_tokens': 67} \n",
      "\n",
      "üí¨  Of course, just look at any of the billion devices around you that have clocks. Congrats on living in the 21st century, where knowing the time is literally at your fingertips! \n",
      "\n",
      "‚ñ∂Ô∏è Run: 8 / 10\n",
      "‚åö 1.71 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Fri, 20 Dec 2024 08:08:43 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': '5b0bc124-1e0b-440b-b137-ae1caf64eb40', 'x-ratelimit-remaining-requests': '72', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': 'f94f2352-b388-4447-803b-065c228a9b6a', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd057-20241120063825', 'x-ms-region': 'UK South', 'x-envoy-upstream-service-time': '1403', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '2720', 'Request-Context': 'appId=cid-v1:09361747-7755-43ae-af86-c2327d97eef2'}\n",
      "x-ms-region: \u001b[1;31mUK South\u001b[0m\n",
      "Token usage: {'completion_tokens': 47, 'prompt_tokens': 30, 'total_tokens': 77} \n",
      "\n",
      "üí¨  Oh, of course! Because who doesn't have the magical ability to just know the time, right? But you might have a device nearby that can help: it‚Äôs called a clock or maybe even a phone. Try one of those! \n",
      "\n",
      "‚ñ∂Ô∏è Run: 9 / 10\n",
      "‚åö 2.44 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Fri, 20 Dec 2024 08:08:45 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'e1341b60-1d2e-4615-aa8f-2594a5549595', 'x-ratelimit-remaining-requests': '79', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '9efa5745-38f1-42b6-8f96-ea49bfe4dbf7', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd066-20241120171340', 'x-ms-region': 'France Central', 'x-envoy-upstream-service-time': '1779', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '7340', 'Request-Context': 'appId=cid-v1:09361747-7755-43ae-af86-c2327d97eef2'}\n",
      "x-ms-region: \u001b[1;31mFrance Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 43, 'prompt_tokens': 30, 'total_tokens': 73} \n",
      "\n",
      "üí¨  Oh, sure! I'd love to tell you the time, but unfortunately, I'm stuck in a timeless bubble here. Maybe try checking one of those magical devices with clocks on them‚Äîlike a phone or a watch! \n",
      "\n",
      "‚ñ∂Ô∏è Run: 10 / 10\n",
      "‚åö 1.32 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {'Content-Type': 'application/json', 'Date': 'Fri, 20 Dec 2024 08:08:46 GMT', 'Cache-Control': 'private', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'apim-request-id': 'a38e422d-aaa4-40f7-bfb9-ac7732a6737b', 'x-ratelimit-remaining-requests': '79', 'x-accel-buffering': 'no', 'x-ms-rai-invoked': 'true', 'X-Request-ID': '296c090f-a285-4e6f-865e-6b0416b5a742', 'X-Content-Type-Options': 'nosniff', 'azureml-model-session': 'd244-20241217044800', 'x-ms-region': 'Sweden Central', 'x-envoy-upstream-service-time': '821', 'x-ms-client-request-id': 'Not-Set', 'x-ratelimit-remaining-tokens': '7340', 'Request-Context': 'appId=cid-v1:09361747-7755-43ae-af86-c2327d97eef2'}\n",
      "x-ms-region: \u001b[1;31mSweden Central\u001b[0m\n",
      "Token usage: {'completion_tokens': 47, 'prompt_tokens': 30, 'total_tokens': 77} \n",
      "\n",
      "üí¨  Oh, of course! Let me just check my non-existent watch! I can definitely pretend to tell you the time if that helps. But seriously, why not try looking at a clock or your phone? That's usually the best bet. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "runs = 10\n",
    "url = apim_resource_gateway_url + \"/openai/deployments/\" + openai_deployment_name + \"/chat/completions?api-version=\" + openai_api_version\n",
    "api_runs = []\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"‚ñ∂Ô∏è Run:\", i+1, \"/\", runs)\n",
    "    \n",
    "\n",
    "    messages={\"messages\":[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]}\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, headers = {'api-key':apim_subscription_key_1}, json = messages)\n",
    "    response_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚åö {response_time:.2f} seconds\")\n",
    "    # Check the response status code and apply formatting\n",
    "    if 200 <= response.status_code < 300:\n",
    "        status_code_str = '\\x1b[1;32m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and green\n",
    "    elif response.status_code >= 400:\n",
    "        status_code_str = '\\x1b[1;31m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and red\n",
    "    else:\n",
    "        status_code_str = str(response.status_code)  # No formatting\n",
    "\n",
    "    # Print the response status with the appropriate formatting\n",
    "    print(\"Response status:\", status_code_str)\n",
    "    \n",
    "    print(\"Response headers:\", response.headers)\n",
    "    \n",
    "    if \"x-ms-region\" in response.headers:\n",
    "        print(\"x-ms-region:\", '\\x1b[1;31m'+response.headers.get(\"x-ms-region\")+'\\x1b[0m') # this header is useful to determine the region of the backend that served the request\n",
    "        api_runs.append((response_time, response.headers.get(\"x-ms-region\")))\n",
    "    \n",
    "    if (response.status_code == 200):\n",
    "        data = json.loads(response.text)\n",
    "        print(\"Token usage:\", data.get(\"usage\"), \"\\n\")\n",
    "        print(\"üí¨ \", data.get(\"choices\")[0].get(\"message\").get(\"content\"), \"\\n\")\n",
    "    else:\n",
    "        print(response.text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Run:  1\n",
      "‚åö 0.81 seconds\n",
      "üí¨  Oh, because I'm just a clock, right? Sorry, I can't help with that. Maybe try looking at a watch or, you know, your phone?\n",
      "‚ñ∂Ô∏è Run:  2\n",
      "‚åö 2.08 seconds\n",
      "üí¨  Sure, let me just check my watch‚Äîoh wait, I don't have one. You might want to try looking at a clock or your phone for that sort of thing.\n",
      "‚ñ∂Ô∏è Run:  3\n",
      "‚åö 0.91 seconds\n",
      "üí¨  Sure, let me just consult my magical, all-seeing clock... Oh wait, I can't do that! You'll have to check a clock or a smartphone like everyone else.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "runs = 3\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"‚ñ∂Ô∏è Run: \", i+1)\n",
    "\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=apim_resource_gateway_url,\n",
    "        api_key=apim_subscription_key_3,\n",
    "        api_version=openai_api_version\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages)\n",
    "    \n",
    "    response_time = time.time() - start_time\n",
    "    print(f\"‚åö {response_time:.2f} seconds\")\n",
    "    print(\"üí¨ \", response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Analyze Application Insights requests\n",
    "\n",
    "With this query you can get the request and response details including the prompt and the OpenAI completion. It also returns token counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>apiName</th>\n",
       "      <th>apimSubscription</th>\n",
       "      <th>duration</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>model</th>\n",
       "      <th>messages</th>\n",
       "      <th>completion</th>\n",
       "      <th>region</th>\n",
       "      <th>promptTokens</th>\n",
       "      <th>completionTokens</th>\n",
       "      <th>totalTokens</th>\n",
       "      <th>remainingTokens</th>\n",
       "      <th>remainingRequests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-20T08:06:04.6253489Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>1.27</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-20T08:06:04.4222185Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>1.34</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-20T08:06:04.2317649Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-20T08:06:04.0442765Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>0.92</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-20T08:06:03.841148Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>2.41</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-12-20T08:06:03.6224058Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>0.85</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-12-20T08:06:03.4036503Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>1.78</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-12-20T08:06:03.216148Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>1.05</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-12-20T08:06:02.9973941Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>1.07</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-12-20T08:06:01.8880568Z</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>922.18</td>\n",
       "      <td>python-requests/2.32.3</td>\n",
       "      <td></td>\n",
       "      <td>[{\"role\":\"system\",\"content\":\"You are a sarcast...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp           apiName  \\\n",
       "0  2024-12-20T08:06:04.6253489Z  api-azure-openai   \n",
       "1  2024-12-20T08:06:04.4222185Z  api-azure-openai   \n",
       "2  2024-12-20T08:06:04.2317649Z  api-azure-openai   \n",
       "3  2024-12-20T08:06:04.0442765Z  api-azure-openai   \n",
       "4   2024-12-20T08:06:03.841148Z  api-azure-openai   \n",
       "5  2024-12-20T08:06:03.6224058Z  api-azure-openai   \n",
       "6  2024-12-20T08:06:03.4036503Z  api-azure-openai   \n",
       "7   2024-12-20T08:06:03.216148Z  api-azure-openai   \n",
       "8  2024-12-20T08:06:02.9973941Z  api-azure-openai   \n",
       "9  2024-12-20T08:06:01.8880568Z  api-azure-openai   \n",
       "\n",
       "                       apimSubscription  duration               userAgent  \\\n",
       "0  3e8b2a2c-04d4-4d6d-b188-17c063154ed3      1.27  python-requests/2.32.3   \n",
       "1  3e8b2a2c-04d4-4d6d-b188-17c063154ed3      1.34  python-requests/2.32.3   \n",
       "2  3e8b2a2c-04d4-4d6d-b188-17c063154ed3      0.95  python-requests/2.32.3   \n",
       "3  3e8b2a2c-04d4-4d6d-b188-17c063154ed3      0.92  python-requests/2.32.3   \n",
       "4  3e8b2a2c-04d4-4d6d-b188-17c063154ed3      2.41  python-requests/2.32.3   \n",
       "5  3e8b2a2c-04d4-4d6d-b188-17c063154ed3      0.85  python-requests/2.32.3   \n",
       "6  3e8b2a2c-04d4-4d6d-b188-17c063154ed3      1.78  python-requests/2.32.3   \n",
       "7  3e8b2a2c-04d4-4d6d-b188-17c063154ed3      1.05  python-requests/2.32.3   \n",
       "8  3e8b2a2c-04d4-4d6d-b188-17c063154ed3      1.07  python-requests/2.32.3   \n",
       "9  3e8b2a2c-04d4-4d6d-b188-17c063154ed3    922.18  python-requests/2.32.3   \n",
       "\n",
       "  model                                           messages completion region  \\\n",
       "0        [{\"role\":\"system\",\"content\":\"You are a sarcast...                     \n",
       "1        [{\"role\":\"system\",\"content\":\"You are a sarcast...                     \n",
       "2        [{\"role\":\"system\",\"content\":\"You are a sarcast...                     \n",
       "3        [{\"role\":\"system\",\"content\":\"You are a sarcast...                     \n",
       "4        [{\"role\":\"system\",\"content\":\"You are a sarcast...                     \n",
       "5        [{\"role\":\"system\",\"content\":\"You are a sarcast...                     \n",
       "6        [{\"role\":\"system\",\"content\":\"You are a sarcast...                     \n",
       "7        [{\"role\":\"system\",\"content\":\"You are a sarcast...                     \n",
       "8        [{\"role\":\"system\",\"content\":\"You are a sarcast...                     \n",
       "9        [{\"role\":\"system\",\"content\":\"You are a sarcast...                     \n",
       "\n",
       "  promptTokens completionTokens totalTokens remainingTokens remainingRequests  \n",
       "0                                                                              \n",
       "1                                                                              \n",
       "2                                                                              \n",
       "3                                                                              \n",
       "4                                                                              \n",
       "5                                                                              \n",
       "6                                                                              \n",
       "7                                                                              \n",
       "8                                                                              \n",
       "9                                                                              "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"requests  \\\n",
    "| project timestamp, duration, customDimensions \\\n",
    "| extend duration = round(duration, 2) \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend apiName = tostring(parsedCustomDimensions.['API Name']) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription Name']) \\\n",
    "| extend userAgent = tostring(parsedCustomDimensions.['Request-User-agent']) \\\n",
    "| extend request_json = tostring(parsedCustomDimensions.['Request-Body']) \\\n",
    "| extend request = parse_json(request_json) \\\n",
    "| extend model = tostring(request.['model']) \\\n",
    "| extend messages = tostring(request.['messages']) \\\n",
    "| extend region = tostring(parsedCustomDimensions.['Response-x-ms-region']) \\\n",
    "| extend remainingTokens = tostring(parsedCustomDimensions.['Response-x-ratelimit-remaining-tokens']) \\\n",
    "| extend remainingRequests = tostring(parsedCustomDimensions.['Response-x-ratelimit-remaining-requests']) \\\n",
    "| extend response_json = tostring(parsedCustomDimensions.['Response-Body']) \\\n",
    "| extend response = parse_json(response_json) \\\n",
    "| extend promptTokens = tostring(response.['usage'].['prompt_tokens']) \\\n",
    "| extend completionTokens = tostring(response.['usage'].['completion_tokens']) \\\n",
    "| extend totalTokens = tostring(response.['usage'].['total_tokens']) \\\n",
    "| extend completion = tostring(response.['choices'][0].['message'].['content']) \\\n",
    "| project timestamp, apiName, apimSubscription, duration, userAgent, model, messages, completion, region, promptTokens, completionTokens, totalTokens, remainingTokens, remainingRequests \\\n",
    "| order by timestamp desc\" + \"\\\"\"\n",
    "\n",
    "result_stdout = !  az monitor app-insights query --app {app_insights_app_id} --analytics-query {query} \n",
    "result = json.loads(result_stdout.n)\n",
    "\n",
    "table = result.get('tables')[0]\n",
    "pd.DataFrame(table.get(\"rows\"), columns=[col.get(\"name\") for col in table.get('columns')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='portal'></a>\n",
    "### üîç Open the workbook in the Azure Portal\n",
    "\n",
    "Go to the application insights resource and under the Monitoring section select the Workbooks blade. You should see the OpenAI Usage Analysis workbook with the above query and some others to check token counts, performance, failures, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Execute multiple runs for each subscription using the Azure OpenAI Python SDK\n",
    "\n",
    "We will send requests for each subscription. Adjust the `sleep_time_ms` and the number of `runs` to your test scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Run:  1\n",
      "üí¨  for subscription 1:  Oh, of course! Because I'm sure someone who controls the space-time continuum forgot to give you a clock. Just check any one of the thousand devices around you.\n",
      "üí¨  for subscription 2:  Oh, sure, let me just pull out my trusty time-traveling watch... oh wait, I don't have one! You might want to try looking at a clock or a phone for that kind of groundbreaking information.\n",
      "üí¨  for subscription 3:  Oh, of course! Let me just magically look at the clock for you! Just kidding, I have no idea what time it is. Maybe check a clock?\n",
      "‚ñ∂Ô∏è Run:  2\n",
      "üí¨  for subscription 1:  Oh, of course! I can definitely tell you the time... if only I had a real sense of time. Sadly, I'm just an AI without a watch. You'll have to rely on that handy clock on your device. Isn't technology grand?\n",
      "üí¨  for subscription 2:  Sure, let me just check my imaginary watch... Oh, wait! I forgot, I'm an AI and don't have one. Maybe try looking at your own device?\n",
      "üí¨  for subscription 3:  Oh, of course! Because I'm totally next to you with a watch, just waiting to provide the time. Sorry, you might need to check a clock or your phone for that one!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "runs = 2\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"‚ñ∂Ô∏è Run: \", i+1)\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription_key_1, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"üí¨ \",\"for subscription 1: \", response.choices[0].message.content)\n",
    "\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription_key_2, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"üí¨ \",\"for subscription 2: \", response.choices[0].message.content)\n",
    "\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription_key_3, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"üí¨ \",\"for subscription 3: \", response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Analyze Application Insights custom metrics with a KQL query\n",
    "\n",
    "With this query you can get the custom metrics that were emitted by Azure APIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>clientIP</th>\n",
       "      <th>apiId</th>\n",
       "      <th>apimSubscription</th>\n",
       "      <th>UserId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08:08</td>\n",
       "      <td>742</td>\n",
       "      <td>176.177.25.47</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>3e8b2a2c-04d4-4d6d-b188-17c063154ed3</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08:09</td>\n",
       "      <td>412</td>\n",
       "      <td>176.177.25.47</td>\n",
       "      <td>api-azure-openai</td>\n",
       "      <td>c6a0b2b6-6e60-47f9-8622-0aaf1759de86</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp  value       clientIP             apiId  \\\n",
       "0     08:08    742  176.177.25.47  api-azure-openai   \n",
       "1     08:09    412  176.177.25.47  api-azure-openai   \n",
       "\n",
       "                       apimSubscription UserId  \n",
       "0  3e8b2a2c-04d4-4d6d-b188-17c063154ed3    N/A  \n",
       "1  c6a0b2b6-6e60-47f9-8622-0aaf1759de86    N/A  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "query = \"\\\"\" + \"customMetrics  \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend clientIP = tostring(parsedCustomDimensions.['Client IP']) \\\n",
    "| extend apiId = tostring(parsedCustomDimensions.['API ID']) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| extend UserId = tostring(parsedCustomDimensions.['User ID']) \\\n",
    "| project timestamp, value, clientIP, apiId, apimSubscription, UserId \\\n",
    "| order by timestamp asc\" + \"\\\"\"\n",
    "\n",
    "result_stdout = ! az monitor app-insights query --app {app_insights_resource_name} -g {resource_group_name} --analytics-query {query} \n",
    "result = json.loads(result_stdout.n)\n",
    "\n",
    "table = result.get('tables')[0]\n",
    "df = pd.DataFrame(table.get(\"rows\"), columns=[col.get(\"name\") for col in table.get('columns')])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%H:%M')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View logs and metrics on Azure Managed Grafana dashboard\n",
    "\n",
    "You can also view the logs and metrics on the Azure Managed Grafana dashboard. Navigate to the Azure Managed Grafana. Login, then go to the dashboards section. Then import the following 2 dashboards:\n",
    "1. Dashboard with ID : 16604 to vider logs and metrics from API Management.\n",
    "2. Dashboard from JSON file [./grafana-dashboard-apim-openai.json](./grafana-dashboard-apim-openai.json) to view logs and metrics from Application Insights.\n",
    "\n",
    "![](images/grafana-dashboard-openai.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
