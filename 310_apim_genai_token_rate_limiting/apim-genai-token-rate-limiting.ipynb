{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Token Rate Limiting lab\n",
    "![flow](../../images/token-rate-limiting.gif)\n",
    "\n",
    "Playground to try the [token rate limiting policy](https://learn.microsoft.com/en-us/azure/api-management/azure-openai-token-limit-policy) to one or more Azure OpenAI endpoints.\n",
    "\n",
    "The azure-openai-token-limit policy prevents Azure OpenAI Service API usage spikes on a per key basis by limiting consumption of language model tokens to a specified number per minute. When the token usage is exceeded, the caller receives a 429 Too Many Requests response status code.\n",
    "\n",
    "### Result\n",
    "![result](result.png)\n",
    "\n",
    "### TOC\n",
    "- [0Ô∏è‚É£ Initialize notebook variables](#0)\n",
    "- [1Ô∏è‚É£ Create the Azure Resource Group](#1)\n",
    "- [2Ô∏è‚É£ Create deployment using ü¶æ Bicep](#2)\n",
    "- [3Ô∏è‚É£ Get the deployment outputs](#3)\n",
    "- [üß™ Test the API using a direct HTTP call](#requests)\n",
    "- [üîç Analyze Token Rate limiting results](#plot)\n",
    "- [üß™ Test the API using the Azure OpenAI Python SDK](#sdk)\n",
    "- [üóëÔ∏è Clean up resources](#clean)\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.8 or later version](https://www.python.org/) installed\n",
    "- [Pandas Library](https://pandas.pydata.org/) and matplotlib installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/en-us/free/) with Contributor permissions\n",
    "- [Access granted to Azure OpenAI](https://aka.ms/oai/access) or just enable the mock service\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using Terraform\n",
    "\n",
    "This lab uses Terraform to declaratively define all the resources that will be deployed. Change the [variables.tf](variables.tf) directly to try different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\n",
      "- Reusing previous version of hashicorp/azurerm from the dependency lock file\n",
      "- Reusing previous version of azure/azapi from the dependency lock file\n",
      "- Using previously-installed azure/azapi v2.1.0\n",
      "- Using previously-installed hashicorp/azurerm v4.14.0\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\n",
      "\u001b[0m\u001b[32m\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
      "any changes that are required for your infrastructure. All Terraform commands\n",
      "should now work.\n",
      "\n",
      "If you ever set or change modules or backend configuration for Terraform,\n",
      "rerun this command to reinitialize your working directory. If you forget, other\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m‚ï∑\u001b[0m\u001b[0m\n",
      "\u001b[31m‚îÇ\u001b[0m \u001b[0m\u001b[1m\u001b[31mError: \u001b[0m\u001b[0m\u001b[1mReference to undeclared resource\u001b[0m\n",
      "\u001b[31m‚îÇ\u001b[0m \u001b[0m\n",
      "\u001b[31m‚îÇ\u001b[0m \u001b[0m\u001b[0m  on apim.tf line 25, in resource \"azurerm_role_assignment\" \"Monitoring-Metrics-Publisher\":\n",
      "\u001b[31m‚îÇ\u001b[0m \u001b[0m  25:   scope                = \u001b[4mazurerm_application_insights.app-insights\u001b[0m.id\u001b[0m\n",
      "\u001b[31m‚îÇ\u001b[0m \u001b[0m\n",
      "\u001b[31m‚îÇ\u001b[0m \u001b[0mA managed resource \"azurerm_application_insights\" \"app-insights\" has not\n",
      "\u001b[31m‚îÇ\u001b[0m \u001b[0mbeen declared in the root module.\n",
      "\u001b[31m‚ïµ\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! terraform init\n",
    "! terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimSubscriptionKey.value -o tsv\n",
    "apim_subscription_key = deployment_stdout.n\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimResourceGatewayURL.value -o tsv\n",
    "apim_resource_gateway_url = deployment_stdout.n\n",
    "print(\"üëâüèª API Gateway URL: \", apim_resource_gateway_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using a direct HTTP call\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior and troubleshoot the [policy](policy.xml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = apim_resource_gateway_url + \"/openai/deployments/\" + openai_deployment_name + \"/chat/completions?api-version=\" + openai_api_version\n",
    "api_runs = []\n",
    "for i in range(10):\n",
    "    messages={\"messages\":[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]}\n",
    "    response = requests.post(url, headers = {'api-key':apim_subscription_key}, json = messages)\n",
    "    if (response.status_code == 200):\n",
    "        print(\"‚ñ∂Ô∏è Run: \", i+1, \"status code: \", response.status_code, \"‚úÖ\")\n",
    "        data = json.loads(response.text)\n",
    "        total_tokens = data.get(\"usage\").get(\"total_tokens\")\n",
    "        print(\"üí¨ \", data.get(\"choices\")[0].get(\"message\").get(\"content\"))\n",
    "    else:\n",
    "        print(\"‚ñ∂Ô∏è Run: \", i+1, \"status code: \", response.status_code, \"‚õî\")\n",
    "        print(response.text)\n",
    "        total_tokens = 0\n",
    "    api_runs.append((total_tokens, response.status_code))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Analyze Token Rate limiting results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "df = pd.DataFrame(api_runs, columns=['Tokens', 'Status Code'])\n",
    "df['Run'] = range(1, len(df) + 1)\n",
    "colors = ['red' if str(code).startswith('5') else 'yellow' if str(code).startswith('4') else 'lightblue' for code in df['Status Code']]\n",
    "ax = df.plot(kind='bar', x='Run', y='Tokens', color=colors, legend=False)\n",
    "plt.title('Rate Limiting results')\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Tokens')\n",
    "plt.xticks(df['Run'], rotation=0)\n",
    "for i, val in enumerate(df['Status Code']):\n",
    "    ax.text(i, 20, '' if int(val) == 200 else 'Status:429', ha='center', va='bottom')\n",
    "for i, val in enumerate(df['Tokens']):\n",
    "    ax.text(i, df['Tokens'][i] + 5, '' if int(val) == 0 else int(val), ha='center', va='bottom')\n",
    "accumulated_tokens = df['Tokens'].cumsum()\n",
    "ax.plot(df['Run']-1, accumulated_tokens, color='green', label='Accumulated Tokens')\n",
    "for i, val in enumerate(accumulated_tokens):\n",
    "    ax.text(i, val + 6, int(val), ha='center', va='bottom', label='Accumulated Tokens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "We want confirm with this test that the SDK is performing retries automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "for i in range(10):\n",
    "    print(\"‚ñ∂Ô∏è Run: \", i+1)\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=apim_resource_gateway_url,\n",
    "        api_key=apim_subscription_key,\n",
    "        api_version=openai_api_version\n",
    "    )\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages)\n",
    "    print(\"üí¨ \",response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
