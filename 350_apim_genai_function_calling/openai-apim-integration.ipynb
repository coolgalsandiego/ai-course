{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI integration into APIM: function calling\n",
    "\n",
    "Playground to try the OpenAI [function calling](https://learn.microsoft.com/azure/ai-services/openai/how-to/function-calling?tabs=non-streaming%2Cpython) feature with an Azure Functions API also managed with APIM. \n",
    "\n",
    "At a high level you can break down working with functions into three steps:\n",
    "1. Call the chat completions API with your functions and the user‚Äôs input\n",
    "2. Use the model‚Äôs response to call your API or function\n",
    "3. Call the chat completions API again, including the response from your function to get a final response\n",
    "\n",
    "![](images/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Create deployment using Terraform\n",
    "\n",
    "This lab uses Terraform to declaratively define all the resources that will be deployed. Change the [variables.tf](variables.tf) directly to try different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! terraform init\n",
    "! terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following resources will be created:\n",
    "\n",
    "![](images/resources.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâüèª APIM Resource Gateway URL:  https://apim-genai-301.azure-api.net\n",
      "üëâüèª APIM Subscription Key:  7e92dc39d04a47bcb7759c4ad7ef644e\n"
     ]
    }
   ],
   "source": [
    "apim_resource_gateway_url = ! terraform output -raw apim_resource_gateway_url\n",
    "apim_resource_gateway_url = apim_resource_gateway_url.n\n",
    "print(\"üëâüèª APIM Resource Gateway URL: \", apim_resource_gateway_url)\n",
    "\n",
    "apim_subscription_key = ! terraform output -raw apim_subscription_key\n",
    "apim_subscription_key = apim_subscription_key.n\n",
    "print(\"üëâüèª APIM Subscription Key: \", apim_subscription_key)\n",
    "\n",
    "openai_api_version = \"2024-10-21\"\n",
    "openai_model_name = \"gpt-4o\"\n",
    "openai_deployment_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Deploy the function\n",
    "\n",
    "Deploy the local function project to the function app resource previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ./function-app\n",
    "! func azure functionapp publish {function_app_resource_name}\n",
    "! cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ üß™ Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Token usage: {'completion_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 30, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 66} \n",
      "\n",
      "üí¨  Oh, sure. Let me just consult my crystal ball... Oh wait, I forgot, I'm *not* a clock. Look at your own device‚Äîyou're clearly using one. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "url = apim_resource_gateway_url + \"/openai/deployments/\" + openai_deployment_name + \"/chat/completions?api-version=\" + openai_api_version\n",
    "\n",
    "messages={\"messages\":[\n",
    "    {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "]}\n",
    "\n",
    "response = requests.post(url, headers = {'api-key':apim_subscription_key}, json = messages)\n",
    "\n",
    "# Check the response status code and apply formatting\n",
    "if 200 <= response.status_code < 300:\n",
    "    status_code_str = '\\x1b[1;32m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and green\n",
    "elif response.status_code >= 400:\n",
    "    status_code_str = '\\x1b[1;31m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and red\n",
    "else:\n",
    "    status_code_str = str(response.status_code)  # No formatting\n",
    "    \n",
    "# Print the response status with the appropriate formatting\n",
    "print(\"Response status:\", status_code_str)\n",
    "\n",
    "if (response.status_code == 200):\n",
    "    data = json.loads(response.text)\n",
    "    print(\"Token usage:\", data.get(\"usage\"), \"\\n\")\n",
    "    print(\"üí¨ \", data.get(\"choices\")[0].get(\"message\").get(\"content\"), \"\\n\")\n",
    "else:\n",
    "    print(response.text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨  Oh, sure, because I‚Äôm obviously your personal talking clock. Why don‚Äôt you just look at a watch, your phone, or literally any clock around you? Genius idea, huh?\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "]\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=apim_resource_gateway_url,\n",
    "    api_key=apim_subscription_key,\n",
    "    api_version=openai_api_version\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(model=openai_model_name, messages=messages)\n",
    "\n",
    "print(\"üí¨ \", response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
