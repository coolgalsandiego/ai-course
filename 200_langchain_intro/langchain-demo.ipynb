{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangChain\n",
    "\n",
    "In this quickstart we'll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it's just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You will need to provision the following Azure resources:\n",
    "* Azure OpenAI with two models: GPT-4o and Embedding model.\n",
    "* Azure AI Search.\n",
    "You can run the terraform template from folder `../400_azure_ai_foundry` to create all of these resources by simply running the following commands.\n",
    "\n",
    "```sh\n",
    "terraform init\n",
    "terraform plan -out tfplan\n",
    "terraform apply tfplan\n",
    "```\n",
    "\n",
    "Then you will need to setup the values for the environment variables in file `.env`.\n",
    "\n",
    "The following resources should be created.\n",
    "\n",
    "![](images/resources.png)\n",
    "\n",
    "To install LangChain run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hodellai\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"langchain[openai]\"\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn how to use a language model by itself. LangChain supports many different language models like OpenAI, Anthropic, Mistral, etc, that you can use interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"lc\": 1,\n",
      "    \"type\": \"constructor\",\n",
      "    \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "    ],\n",
      "    \"kwargs\": {\n",
      "        \"content\": \"Hello, world! \\ud83c\\udf0d How can I assist you today?\",\n",
      "        \"additional_kwargs\": {\n",
      "            \"refusal\": null\n",
      "        },\n",
      "        \"response_metadata\": {\n",
      "            \"token_usage\": {\n",
      "                \"completion_tokens\": 13,\n",
      "                \"prompt_tokens\": 11,\n",
      "                \"total_tokens\": 24,\n",
      "                \"completion_tokens_details\": {\n",
      "                    \"accepted_prediction_tokens\": 0,\n",
      "                    \"audio_tokens\": 0,\n",
      "                    \"reasoning_tokens\": 0,\n",
      "                    \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                    \"audio_tokens\": 0,\n",
      "                    \"cached_tokens\": 0\n",
      "                }\n",
      "            },\n",
      "            \"model_name\": \"gpt-4o-2024-11-20\",\n",
      "            \"system_fingerprint\": \"fp_b705f0c291\",\n",
      "            \"prompt_filter_results\": [\n",
      "                {\n",
      "                    \"prompt_index\": 0,\n",
      "                    \"content_filter_results\": {\n",
      "                        \"hate\": {\n",
      "                            \"filtered\": false,\n",
      "                            \"severity\": \"safe\"\n",
      "                        },\n",
      "                        \"jailbreak\": {\n",
      "                            \"filtered\": false,\n",
      "                            \"detected\": false\n",
      "                        },\n",
      "                        \"self_harm\": {\n",
      "                            \"filtered\": false,\n",
      "                            \"severity\": \"safe\"\n",
      "                        },\n",
      "                        \"sexual\": {\n",
      "                            \"filtered\": false,\n",
      "                            \"severity\": \"safe\"\n",
      "                        },\n",
      "                        \"violence\": {\n",
      "                            \"filtered\": false,\n",
      "                            \"severity\": \"safe\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            ],\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"logprobs\": null,\n",
      "            \"content_filter_results\": {\n",
      "                \"hate\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"protected_material_code\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"detected\": false\n",
      "                },\n",
      "                \"protected_material_text\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"detected\": false\n",
      "                },\n",
      "                \"self_harm\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"sexual\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"violence\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"type\": \"ai\",\n",
      "        \"id\": \"run-2c815767-2f68-41a0-a331-17d1c857de52-0\",\n",
      "        \"usage_metadata\": {\n",
      "            \"input_tokens\": 11,\n",
      "            \"output_tokens\": 13,\n",
      "            \"total_tokens\": 24,\n",
      "            \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "            },\n",
      "            \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "            }\n",
      "        },\n",
      "        \"tool_calls\": [],\n",
      "        \"invalid_tool_calls\": []\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "if os.path.exists(\".env\"):\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    openai_api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "response = model.invoke(\"Hello, world!\")\n",
    "\n",
    "# format json response\n",
    "json_formatted_str = json.dumps(response.to_json(), indent=4)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a message with system and human input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"lc\": 1,\n",
      "    \"type\": \"constructor\",\n",
      "    \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"messages\",\n",
      "        \"AIMessage\"\n",
      "    ],\n",
      "    \"kwargs\": {\n",
      "        \"content\": \"Ciao!\",\n",
      "        \"additional_kwargs\": {\n",
      "            \"refusal\": null\n",
      "        },\n",
      "        \"response_metadata\": {\n",
      "            \"token_usage\": {\n",
      "                \"completion_tokens\": 3,\n",
      "                \"prompt_tokens\": 20,\n",
      "                \"total_tokens\": 23,\n",
      "                \"completion_tokens_details\": {\n",
      "                    \"accepted_prediction_tokens\": 0,\n",
      "                    \"audio_tokens\": 0,\n",
      "                    \"reasoning_tokens\": 0,\n",
      "                    \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                    \"audio_tokens\": 0,\n",
      "                    \"cached_tokens\": 0\n",
      "                }\n",
      "            },\n",
      "            \"model_name\": \"gpt-4o-2024-11-20\",\n",
      "            \"system_fingerprint\": \"fp_b705f0c291\",\n",
      "            \"prompt_filter_results\": [\n",
      "                {\n",
      "                    \"prompt_index\": 0,\n",
      "                    \"content_filter_results\": {\n",
      "                        \"hate\": {\n",
      "                            \"filtered\": false,\n",
      "                            \"severity\": \"safe\"\n",
      "                        },\n",
      "                        \"jailbreak\": {\n",
      "                            \"filtered\": false,\n",
      "                            \"detected\": false\n",
      "                        },\n",
      "                        \"self_harm\": {\n",
      "                            \"filtered\": false,\n",
      "                            \"severity\": \"safe\"\n",
      "                        },\n",
      "                        \"sexual\": {\n",
      "                            \"filtered\": false,\n",
      "                            \"severity\": \"safe\"\n",
      "                        },\n",
      "                        \"violence\": {\n",
      "                            \"filtered\": false,\n",
      "                            \"severity\": \"safe\"\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            ],\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"logprobs\": null,\n",
      "            \"content_filter_results\": {\n",
      "                \"hate\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"protected_material_code\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"detected\": false\n",
      "                },\n",
      "                \"protected_material_text\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"detected\": false\n",
      "                },\n",
      "                \"self_harm\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"sexual\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"violence\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"type\": \"ai\",\n",
      "        \"id\": \"run-54fc30d7-262b-4930-8da4-4a03b222bf77-0\",\n",
      "        \"usage_metadata\": {\n",
      "            \"input_tokens\": 20,\n",
      "            \"output_tokens\": 3,\n",
      "            \"total_tokens\": 23,\n",
      "            \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "            },\n",
      "            \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "            }\n",
      "        },\n",
      "        \"tool_calls\": [],\n",
      "        \"invalid_tool_calls\": []\n",
      "    }\n",
      "}\n",
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# format json response\n",
    "json_formatted_str = json.dumps(response.to_json(), indent=4)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print just the response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain also supports chat model inputs via strings or OpenAI format. The following are equivalent:\n",
    "```python\n",
    "model.invoke(\"Hello\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"Hello\")])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stream the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||C|iao|!||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Prompt Templates in LangChain\n",
    "\n",
    "### Defining the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a prompt from a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the chat model on the formatted prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More resources\n",
    "\n",
    "https://python.langchain.com/docs/tutorials/llm_chain/\n",
    "\n",
    "https://python.langchain.com/docs/how_to/document_loader_pdf/\n",
    "\n",
    "https://python.langchain.com/docs/how_to/semantic-chunker/\n",
    "\n",
    "https://langchain-opentutorial.gitbook.io/langchain-opentutorial/07-textsplitter/04-semanticchunker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
