{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Azure OpenAI GPT models\n",
    "\n",
    "This sample demonstrates how to get started with Azure OpenAI Chat Completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai --quiet\n",
    "%pip install python-dotenv --quiet\n",
    "%pip install numpy --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the environment variables from the `.env` file to connect to the LLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "if os.path.exists(\".env\"):\n",
    "    load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a chat completion service\n",
    "\n",
    ">Note: The AzureChatCompletion service also supports Microsoft Entra authentication. If you don't provide an API key, the service will attempt to authenticate using the Entra token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "endpoint = \"https://ai-services-31293-400003.openai.azure.com/\"\n",
    "subscription_key = \"EfbmGw4MsbvXhItjP6OdrJR6nbjoQj9dWU0FSOf1p26HBNKdXoeMJQQJ99BCACYeBjFXJ3w3AAAAACOGv7IZ\"\n",
    "deployment = \"gpt-4o\"\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    ")\n",
    "\n",
    "# Prepare the chat prompt\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": \"You are an AI assistant that helps people find information.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": \"What is the capital of France?\"\n",
    "    },\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    max_tokens=800,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None,\n",
    "    stream=False,\n",
    "    logprobs=True,\n",
    "    top_logprobs=3\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets view the full JSON response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BD8ggz5NHJ8lfgjYpyIfv3a2BNhlE\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": {\n",
      "        \"content\": [\n",
      "          {\n",
      "            \"token\": \"The\",\n",
      "            \"bytes\": [\n",
      "              84,\n",
      "              104,\n",
      "              101\n",
      "            ],\n",
      "            \"logprob\": 0.0,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \"The\",\n",
      "                \"bytes\": [\n",
      "                  84,\n",
      "                  104,\n",
      "                  101\n",
      "                ],\n",
      "                \"logprob\": 0.0\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"Paris\",\n",
      "                \"bytes\": [\n",
      "                  80,\n",
      "                  97,\n",
      "                  114,\n",
      "                  105,\n",
      "                  115\n",
      "                ],\n",
      "                \"logprob\": -17.0\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" The\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  84,\n",
      "                  104,\n",
      "                  101\n",
      "                ],\n",
      "                \"logprob\": -18.625\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" capital\",\n",
      "            \"bytes\": [\n",
      "              32,\n",
      "              99,\n",
      "              97,\n",
      "              112,\n",
      "              105,\n",
      "              116,\n",
      "              97,\n",
      "              108\n",
      "            ],\n",
      "            \"logprob\": 0.0,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" capital\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  99,\n",
      "                  97,\n",
      "                  112,\n",
      "                  105,\n",
      "                  116,\n",
      "                  97,\n",
      "                  108\n",
      "                ],\n",
      "                \"logprob\": 0.0\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" **\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  42,\n",
      "                  42\n",
      "                ],\n",
      "                \"logprob\": -20.375\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"<|end|>\",\n",
      "                \"bytes\": null,\n",
      "                \"logprob\": -21.71875\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" of\",\n",
      "            \"bytes\": [\n",
      "              32,\n",
      "              111,\n",
      "              102\n",
      "            ],\n",
      "            \"logprob\": 0.0,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" of\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  111,\n",
      "                  102\n",
      "                ],\n",
      "                \"logprob\": 0.0\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" city\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  99,\n",
      "                  105,\n",
      "                  116,\n",
      "                  121\n",
      "                ],\n",
      "                \"logprob\": -19.125\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"<|end|>\",\n",
      "                \"bytes\": null,\n",
      "                \"logprob\": -22.25\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" France\",\n",
      "            \"bytes\": [\n",
      "              32,\n",
      "              70,\n",
      "              114,\n",
      "              97,\n",
      "              110,\n",
      "              99,\n",
      "              101\n",
      "            ],\n",
      "            \"logprob\": -0.000016762922,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" France\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  70,\n",
      "                  114,\n",
      "                  97,\n",
      "                  110,\n",
      "                  99,\n",
      "                  101\n",
      "                ],\n",
      "                \"logprob\": -0.000016762922\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" **\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  42,\n",
      "                  42\n",
      "                ],\n",
      "                \"logprob\": -11.000017\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" ***\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  42,\n",
      "                  42,\n",
      "                  42\n",
      "                ],\n",
      "                \"logprob\": -18.125017\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" is\",\n",
      "            \"bytes\": [\n",
      "              32,\n",
      "              105,\n",
      "              115\n",
      "            ],\n",
      "            \"logprob\": 0.0,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" is\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  105,\n",
      "                  115\n",
      "                ],\n",
      "                \"logprob\": 0.0\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" **\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  42,\n",
      "                  42\n",
      "                ],\n",
      "                \"logprob\": -22.71875\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"<|end|>\",\n",
      "                \"bytes\": null,\n",
      "                \"logprob\": -22.953125\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" **\",\n",
      "            \"bytes\": [\n",
      "              32,\n",
      "              42,\n",
      "              42\n",
      "            ],\n",
      "            \"logprob\": -0.00039909125,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" **\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  42,\n",
      "                  42\n",
      "                ],\n",
      "                \"logprob\": -0.00039909125\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" Paris\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  80,\n",
      "                  97,\n",
      "                  114,\n",
      "                  105,\n",
      "                  115\n",
      "                ],\n",
      "                \"logprob\": -7.875399\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" ***\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  42,\n",
      "                  42,\n",
      "                  42\n",
      "                ],\n",
      "                \"logprob\": -10.875399\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \"Paris\",\n",
      "            \"bytes\": [\n",
      "              80,\n",
      "              97,\n",
      "              114,\n",
      "              105,\n",
      "              115\n",
      "            ],\n",
      "            \"logprob\": 0.0,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \"Paris\",\n",
      "                \"bytes\": [\n",
      "                  80,\n",
      "                  97,\n",
      "                  114,\n",
      "                  105,\n",
      "                  115\n",
      "                ],\n",
      "                \"logprob\": 0.0\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"Par\",\n",
      "                \"bytes\": [\n",
      "                  80,\n",
      "                  97,\n",
      "                  114\n",
      "                ],\n",
      "                \"logprob\": -20.375\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" Paris\",\n",
      "                \"bytes\": [\n",
      "                  32,\n",
      "                  80,\n",
      "                  97,\n",
      "                  114,\n",
      "                  105,\n",
      "                  115\n",
      "                ],\n",
      "                \"logprob\": -20.75\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \"**\",\n",
      "            \"bytes\": [\n",
      "              42,\n",
      "              42\n",
      "            ],\n",
      "            \"logprob\": -0.00023083435,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \"**\",\n",
      "                \"bytes\": [\n",
      "                  42,\n",
      "                  42\n",
      "                ],\n",
      "                \"logprob\": -0.00023083435\n",
      "              },\n",
      "              {\n",
      "                \"token\": \".\",\n",
      "                \"bytes\": [\n",
      "                  46\n",
      "                ],\n",
      "                \"logprob\": -8.375231\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"**,\",\n",
      "                \"bytes\": [\n",
      "                  42,\n",
      "                  42,\n",
      "                  44\n",
      "                ],\n",
      "                \"logprob\": -15.812731\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \".\",\n",
      "            \"bytes\": [\n",
      "              46\n",
      "            ],\n",
      "            \"logprob\": -3.1281633e-7,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \".\",\n",
      "                \"bytes\": [\n",
      "                  46\n",
      "                ],\n",
      "                \"logprob\": -3.1281633e-7\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"!\",\n",
      "                \"bytes\": [\n",
      "                  33\n",
      "                ],\n",
      "                \"logprob\": -15.75\n",
      "              },\n",
      "              {\n",
      "                \"token\": \".\\n\",\n",
      "                \"bytes\": [\n",
      "                  46,\n",
      "                  10\n",
      "                ],\n",
      "                \"logprob\": -16.125\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ],\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"message\": {\n",
      "        \"content\": \"The capital of France is **Paris**.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"protected_material_code\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"protected_material_text\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1742471358,\n",
      "  \"model\": \"gpt-4o-2024-11-20\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_a42ed5ff0c\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 10,\n",
      "    \"prompt_tokens\": 29,\n",
      "    \"total_tokens\": 39,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"jailbreak\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print the full response object\n",
    "print(response.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the probabilities of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style='color: cyan'>Output token 1:</span> The, <span style='color: darkorange'>logprobs:</span> 0.0, <span style='color: magenta'>linear probability:</span> 100.0%<br><span style='color: cyan'>Output token 2:</span> Paris, <span style='color: darkorange'>logprobs:</span> -17.0, <span style='color: magenta'>linear probability:</span> 0.0%<br><span style='color: cyan'>Output token 3:</span>  The, <span style='color: darkorange'>logprobs:</span> -18.625, <span style='color: magenta'>linear probability:</span> 0.0%<br><br><span style='color: cyan'>Output token 1:</span>  capital, <span style='color: darkorange'>logprobs:</span> 0.0, <span style='color: magenta'>linear probability:</span> 100.0%<br><span style='color: cyan'>Output token 2:</span>  **, <span style='color: darkorange'>logprobs:</span> -20.375, <span style='color: magenta'>linear probability:</span> 0.0%<br><span style='color: cyan'>Output token 3:</span> <|end|>, <span style='color: darkorange'>logprobs:</span> -21.71875, <span style='color: magenta'>linear probability:</span> 0.0%<br><br><span style='color: cyan'>Output token 1:</span>  of, <span style='color: darkorange'>logprobs:</span> 0.0, <span style='color: magenta'>linear probability:</span> 100.0%<br><span style='color: cyan'>Output token 2:</span>  city, <span style='color: darkorange'>logprobs:</span> -19.125, <span style='color: magenta'>linear probability:</span> 0.0%<br><span style='color: cyan'>Output token 3:</span> <|end|>, <span style='color: darkorange'>logprobs:</span> -22.25, <span style='color: magenta'>linear probability:</span> 0.0%<br><br><span style='color: cyan'>Output token 1:</span>  France, <span style='color: darkorange'>logprobs:</span> -1.6762922e-05, <span style='color: magenta'>linear probability:</span> 100.0%<br><span style='color: cyan'>Output token 2:</span>  **, <span style='color: darkorange'>logprobs:</span> -11.000017, <span style='color: magenta'>linear probability:</span> 0.0%<br><span style='color: cyan'>Output token 3:</span>  ***, <span style='color: darkorange'>logprobs:</span> -18.125017, <span style='color: magenta'>linear probability:</span> 0.0%<br><br><span style='color: cyan'>Output token 1:</span>  is, <span style='color: darkorange'>logprobs:</span> 0.0, <span style='color: magenta'>linear probability:</span> 100.0%<br><span style='color: cyan'>Output token 2:</span>  **, <span style='color: darkorange'>logprobs:</span> -22.71875, <span style='color: magenta'>linear probability:</span> 0.0%<br><span style='color: cyan'>Output token 3:</span> <|end|>, <span style='color: darkorange'>logprobs:</span> -22.953125, <span style='color: magenta'>linear probability:</span> 0.0%<br><br><span style='color: cyan'>Output token 1:</span>  **, <span style='color: darkorange'>logprobs:</span> -0.00039909125, <span style='color: magenta'>linear probability:</span> 99.96%<br><span style='color: cyan'>Output token 2:</span>  Paris, <span style='color: darkorange'>logprobs:</span> -7.875399, <span style='color: magenta'>linear probability:</span> 0.04%<br><span style='color: cyan'>Output token 3:</span>  ***, <span style='color: darkorange'>logprobs:</span> -10.875399, <span style='color: magenta'>linear probability:</span> 0.0%<br><br><span style='color: cyan'>Output token 1:</span> Paris, <span style='color: darkorange'>logprobs:</span> 0.0, <span style='color: magenta'>linear probability:</span> 100.0%<br><span style='color: cyan'>Output token 2:</span> Par, <span style='color: darkorange'>logprobs:</span> -20.375, <span style='color: magenta'>linear probability:</span> 0.0%<br><span style='color: cyan'>Output token 3:</span>  Paris, <span style='color: darkorange'>logprobs:</span> -20.75, <span style='color: magenta'>linear probability:</span> 0.0%<br><br><span style='color: cyan'>Output token 1:</span> **, <span style='color: darkorange'>logprobs:</span> -0.00023083435, <span style='color: magenta'>linear probability:</span> 99.98%<br><span style='color: cyan'>Output token 2:</span> ., <span style='color: darkorange'>logprobs:</span> -8.375231, <span style='color: magenta'>linear probability:</span> 0.02%<br><span style='color: cyan'>Output token 3:</span> **,, <span style='color: darkorange'>logprobs:</span> -15.812731, <span style='color: magenta'>linear probability:</span> 0.0%<br><br><span style='color: cyan'>Output token 1:</span> ., <span style='color: darkorange'>logprobs:</span> -3.1281633e-07, <span style='color: magenta'>linear probability:</span> 100.0%<br><span style='color: cyan'>Output token 2:</span> !, <span style='color: darkorange'>logprobs:</span> -15.75, <span style='color: magenta'>linear probability:</span> 0.0%<br><span style='color: cyan'>Output token 3:</span> .\n",
       ", <span style='color: darkorange'>logprobs:</span> -16.125, <span style='color: magenta'>linear probability:</span> 0.0%<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "html_content = \"\"\n",
    "\n",
    "for content in response.choices[0].logprobs.content:\n",
    "\n",
    "    top_logprobs = content.top_logprobs\n",
    "\n",
    "    for i, logprob in enumerate(top_logprobs, start=1):\n",
    "        html_content += (\n",
    "            f\"<span style='color: cyan'>Output token {i}:</span> {logprob.token}, \"\n",
    "            f\"<span style='color: darkorange'>logprobs:</span> {logprob.logprob}, \"\n",
    "            f\"<span style='color: magenta'>linear probability:</span> {np.round(np.exp(logprob.logprob)*100,2)}%<br>\"\n",
    "        )\n",
    "\n",
    "    html_content += f\"<br>\"\n",
    "    \n",
    "display(HTML(html_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
