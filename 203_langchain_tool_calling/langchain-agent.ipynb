{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool calling using LangChain\n",
    "\n",
    "Many AI applications interact directly with humans. In these cases, it is appropriate for models to respond in natural language. But what about cases where we want a model to also interact directly with systems, such as databases or an API? These systems often have a particular input schema; for example, APIs frequently have a required payload structure. This need motivates the concept of tool calling. You can use tool calling to request model responses that match a particular schema.\n",
    "\n",
    "## Key concepts\n",
    "\n",
    "1. **Tool Creation:** Use the `@tool` decorator to create a tool. A tool is an association between a function and its schema. \n",
    "2. **Tool Binding:** The tool needs to be connected to a model that supports tool calling. This gives the model awareness of the tool and the associated input schema required by the tool.\n",
    "3. **Tool Calling:** When appropriate, the model can decide to call a tool and ensure its response conforms to the tool's input schema.\n",
    "4. **Tool Execution:** The tool can be executed using the arguments provided by the model.\n",
    "\n",
    "![](images/tool_calling_components.png)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* Azure OpenAI GPT model\n",
    "* Setup `.env` file with the required credentials\n",
    "\n",
    "To install `LangChain` run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-community langgraph --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Language Models\n",
    "\n",
    "Next, let's learn how to use a language model to call tools. LangChain supports many different language models that you can use interchangably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "if os.path.exists(\".env\"):\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    openai_api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool creation\n",
    "\n",
    "The recommended way to create a tool is using the `@tool` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool binding\n",
    "\n",
    "The central concept to understand is that `LangChain` provides a standardized interface for connecting tools to models. The `.bind_tools()` method can be used to specify which tools are available for a model to call.\n",
    "\n",
    "As a specific example, let's take a function multiply and bind it as a tool to a model that supports tool calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = model.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool calling\n",
    "\n",
    "![](images/tool-calling.png)\n",
    "\n",
    "A key principle of tool calling is that the model decides when to use a tool based on the input's relevance. The model doesn't always need to call a tool. For example, given an unrelated input, the model would not call the tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result would be an AIMessage containing the model's response in natural language (e.g., \"Hello!\"). However, if we pass an input relevant to the tool, the model should choose to call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"What is 2 multiplied by 3?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the output result will be an `AIMessage`. But, if the tool was called, result will have a `tool_calls` attribute. This attribute includes everything needed to execute the tool, including the tool name and input arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': 'call_JpJ5kos6mkRCM7kj73AupdbE',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices\n",
    "\n",
    "When designing tools to be used by a model, it is important to keep in mind that:\n",
    "\n",
    "Models that have explicit tool-calling APIs will be better at tool calling than non-fine-tuned models.\n",
    "Models will perform better if the tools have well-chosen names and descriptions.\n",
    "Simple, narrowly scoped tools are easier for models to use than complex tools.\n",
    "Asking the model to select from a large list of tools poses challenges for the model.\n",
    "\n",
    "## More resources\n",
    "\n",
    "https://python.langchain.com/docs/concepts/tool_calling/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
