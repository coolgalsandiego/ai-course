{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel Chat Completion Agent\n",
    "\n",
    "Chat Completion is fundamentally a protocol for a chat-based interaction with an AI model where the chat-history maintained and presented to the model with each request. Semantic Kernel AI services offer a unified framework for integrating the chat-completion capabilities of various AI models.\n",
    "\n",
    "A chat completion agent can leverage any of these AI services to generate responses, whether directed to a user or another agent.\n",
    "\n",
    "\n",
    "## Creating the required Azure resources\n",
    "\n",
    "You can run the powershell script `create-azure-ai-resources.ps1` to create the following resources:\n",
    "* Azure AI Services with Hub and Project\n",
    "* GPT-4o model\n",
    "\n",
    "## Installing the necessary packages\n",
    "\n",
    "Import Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U semantic-kernel --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current version of Semantic Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.23.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "if os.path.exists(\".env\"):\n",
    "    load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a chat completion service\n",
    "\n",
    ">Note: The AzureChatCompletion service also supports Microsoft Entra authentication. If you don't provide an API key, the service will attempt to authenticate using the Entra token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# Add Azure OpenAI chat completion\n",
    "chat_completion = AzureChatCompletion(\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    service_id=\"service1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try chat with LLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "\n",
    "execution_settings = AzureChatPromptExecutionSettings()\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are a helpful assistant that can answer questions and provide information.\n",
    "\"\"\"\n",
    "\n",
    "chat_history = ChatHistory(system_message=system_message)\n",
    "\n",
    "chat_history.add_user_message(\"Hello, how are you?\")\n",
    "\n",
    "response = await chat_completion.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Chat Completion Agent\n",
    "\n",
    "A chat completion agent is fundamentally based on an AI services. As such, creating an chat completion agent starts with creating a Kernel instance that contains one or more chat-completion services and then instantiating the agent with a reference to that Kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "\n",
    "# Define the Kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add the AzureChatCompletion AI Service to the Kernel\n",
    "kernel.add_service(chat_completion)\n",
    "\n",
    "settings = AzureChatPromptExecutionSettings(service_id=\"service1\")\n",
    "\n",
    "# Create the agent\n",
    "agent = ChatCompletionAgent(\n",
    "    kernel=kernel, \n",
    "    name=\"chat-agent\", \n",
    "    instructions=\"You are a helpful agent.\",\n",
    "    arguments=KernelArguments(settings=settings)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversing with ChatCompletionAgent\n",
    "\n",
    "There are multiple ways to converse with a ChatCompletionAgent.\n",
    "\n",
    "The easiest is to call and await get_response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a virtual assistant, but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents import AuthorRole\n",
    "\n",
    "# Define the chat history\n",
    "history = ChatHistory()\n",
    "\n",
    "# Add the user message\n",
    "history.add_message(ChatMessageContent(role=AuthorRole.USER, content=\"Hello, how are you?\"))\n",
    "\n",
    "# Generate the agent response\n",
    "response = await agent.get_response(history)\n",
    "\n",
    "print(f\"{response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Semantic Kernel Plugin\n",
    "\n",
    "Let's create a plugin that interacts with Github API for repositories and users.\n",
    "\n",
    "This plugin example was provided by Microsoft at this link: https://github.com/microsoft/semantic-kernel/blob/main/python/samples/learn_resources/plugins/GithubPlugin/github.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "\n",
    "\n",
    "import httpx\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "\n",
    "# region GitHub Models\n",
    "\n",
    "\n",
    "class Repo(BaseModel):\n",
    "    id: int = Field(..., alias=\"id\")\n",
    "    name: str = Field(..., alias=\"full_name\")\n",
    "    description: str | None = Field(default=None, alias=\"description\")\n",
    "    url: str = Field(..., alias=\"html_url\")\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    id: int = Field(..., alias=\"id\")\n",
    "    login: str = Field(..., alias=\"login\")\n",
    "    name: str | None = Field(default=None, alias=\"name\")\n",
    "    company: str | None = Field(default=None, alias=\"company\")\n",
    "    url: str = Field(..., alias=\"html_url\")\n",
    "\n",
    "\n",
    "class Label(BaseModel):\n",
    "    id: int = Field(..., alias=\"id\")\n",
    "    name: str = Field(..., alias=\"name\")\n",
    "    description: str | None = Field(default=None, alias=\"description\")\n",
    "\n",
    "\n",
    "class Issue(BaseModel):\n",
    "    id: int = Field(..., alias=\"id\")\n",
    "    number: int = Field(..., alias=\"number\")\n",
    "    url: str = Field(..., alias=\"html_url\")\n",
    "    title: str = Field(..., alias=\"title\")\n",
    "    state: str = Field(..., alias=\"state\")\n",
    "    labels: list[Label] = Field(..., alias=\"labels\")\n",
    "    when_created: str | None = Field(default=None, alias=\"created_at\")\n",
    "    when_closed: str | None = Field(default=None, alias=\"closed_at\")\n",
    "\n",
    "\n",
    "class IssueDetail(Issue):\n",
    "    body: str | None = Field(default=None, alias=\"body\")\n",
    "\n",
    "\n",
    "# endregion\n",
    "\n",
    "\n",
    "class GitHubSettings(BaseModel):\n",
    "    base_url: str = \"https://api.github.com\"\n",
    "    token: str\n",
    "\n",
    "\n",
    "class GitHubPlugin:\n",
    "    def __init__(self, settings: GitHubSettings):\n",
    "        self.settings = settings\n",
    "\n",
    "    @kernel_function\n",
    "    async def get_user_profile(self) -> \"User\":\n",
    "        async with self.create_client() as client:\n",
    "            response = await self.make_request(client, \"/user\")\n",
    "            return User(**response)\n",
    "\n",
    "    @kernel_function\n",
    "    async def get_repository(self, organization: str, repo: str) -> \"Repo\":\n",
    "        async with self.create_client() as client:\n",
    "            response = await self.make_request(client, f\"/repos/{organization}/{repo}\")\n",
    "            return Repo(**response)\n",
    "\n",
    "    @kernel_function\n",
    "    async def get_issues(\n",
    "        self,\n",
    "        organization: str,\n",
    "        repo: str,\n",
    "        max_results: int | None = None,\n",
    "        state: str = \"\",\n",
    "        label: str = \"\",\n",
    "        assignee: str = \"\",\n",
    "    ) -> list[\"Issue\"]:\n",
    "        async with self.create_client() as client:\n",
    "            path = f\"/repos/{organization}/{repo}/issues?\"\n",
    "            path = self.build_query(path, \"state\", state)\n",
    "            path = self.build_query(path, \"assignee\", assignee)\n",
    "            path = self.build_query(path, \"labels\", label)\n",
    "            path = self.build_query(path, \"per_page\", str(max_results) if max_results else \"\")\n",
    "            response = await self.make_request(client, path)\n",
    "            return [Issue(**issue) for issue in response]\n",
    "\n",
    "    @kernel_function\n",
    "    async def get_issue_detail(self, organization: str, repo: str, issue_id: int) -> \"IssueDetail\":\n",
    "        async with self.create_client() as client:\n",
    "            path = f\"/repos/{organization}/{repo}/issues/{issue_id}\"\n",
    "            response = await self.make_request(client, path)\n",
    "            return IssueDetail(**response)\n",
    "\n",
    "    def create_client(self) -> httpx.AsyncClient:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"request\",\n",
    "            \"Accept\": \"application/vnd.github+json\",\n",
    "            \"Authorization\": f\"Bearer {self.settings.token}\",\n",
    "            \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
    "        }\n",
    "        return httpx.AsyncClient(base_url=self.settings.base_url, headers=headers, timeout=5)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_query(path: str, key: str, value: str) -> str:\n",
    "        if value:\n",
    "            return f\"{path}{key}={value}&\"\n",
    "        return path\n",
    "\n",
    "    @staticmethod\n",
    "    async def make_request(client: httpx.AsyncClient, path: str) -> dict:\n",
    "        print(f\"REQUEST: {path}\\n\")\n",
    "        response = await client.get(path)\n",
    "        response.raise_for_status()\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Definition\n",
    "\n",
    "Finally we are ready to instantiate a ChatCompletionAgent with its Instructions, associated Kernel, and the default Arguments and Execution Settings. In this case, we desire to have the any plugin functions automatically executed.\n",
    "\n",
    ">You will need to define settings for either OpenAI or Azure OpenAI and also for GitHub.\n",
    "\n",
    ">Note: For information on GitHub Personal Access Tokens, see: [Managing your personal access tokens](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "# Import GitHubPlugin and GitHubSettings directly from the notebook\n",
    "from __main__ import GitHubPlugin, GitHubSettings\n",
    "\n",
    "kernel = Kernel()\n",
    "# Add the AzureChatCompletion AI Service to the Kernel\n",
    "service_id = \"agent\"\n",
    "kernel.add_service(AzureChatCompletion(service_id=service_id))\n",
    "\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(service_id=service_id)\n",
    "# Configure the function choice behavior to auto invoke kernel functions\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Set your GitHub Personal Access Token (PAT) value here\n",
    "gh_settings = GitHubSettings(token=os.getenv(\"GITHUB_PAT\"))\n",
    "\n",
    "kernel.add_plugin(plugin=GitHubPlugin(gh_settings), plugin_name=\"GithubPlugin\")\n",
    "\n",
    "# Create the agent\n",
    "agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"SampleAssistantAgent\",\n",
    "    instructions=f\"\"\"\n",
    "        You are an agent designed to query and retrieve information from a single GitHub repository in a read-only manner.\n",
    "        You are also able to access the profile of the active user.\n",
    "        Use the current date and time to provide up-to-date details or time-sensitive responses.\n",
    "        The repository you are querying is a public repository with the following name: HoussemDellai/ai-course\n",
    "        The current date and time is: {{$now}}. \n",
    "        \"\"\",\n",
    "    arguments=KernelArguments(settings=settings),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the username of the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUEST: /user\n",
      "\n",
      "Your username is **HoussemDellai**.\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from datetime import datetime\n",
    "\n",
    "history = ChatHistory()\n",
    "\n",
    "user_input = \"What is my username?\"\n",
    "\n",
    "history.add_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "\n",
    "arguments = KernelArguments(now=datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "async for response in agent.invoke(history=history, arguments=arguments):\n",
    "    print(f\"{response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUEST: /repos/HoussemDellai/ai-course\n",
      "\n",
      "The repository **HoussemDellai/ai-course** is focused on \"Learning Azure AI with APIM, Semantic Kernel and LangChain.\" You can visit the repository for more details [here](https://github.com/HoussemDellai/ai-course).\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Describe the repo.\"\n",
    "\n",
    "history.add_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "\n",
    "arguments = KernelArguments(now=datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "async for response in agent.invoke(history=history, arguments=arguments):\n",
    "    print(f\"{response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the newest issue created in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUEST: /repos/HoussemDellai/ai-course/issues?state=open&per_page=1&\n",
      "\n",
      "The newest issue created in the repository \"HoussemDellai/ai-course\" is titled \"[Creating issue just for testing in a chat agent](https://github.com/HoussemDellai/ai-course/issues/1).\" It is currently open and was created on March 7, 2025. The issue is labeled as a \"bug\" with the description \"Something isn't working.\"\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Describe the newest issue created in the repo.\"\n",
    "\n",
    "history.add_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "\n",
    "arguments = KernelArguments(now=datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "async for response in agent.invoke(history=history, arguments=arguments):\n",
    "    print(f\"{response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the top 10 issues closed within the last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUEST: /repos/HoussemDellai/ai-course/issues?state=closed&per_page=10&\n",
      "\n",
      "Here is the top issue that was closed within the last week in the repository \"HoussemDellai/ai-course\":\n",
      "\n",
      "1. **Title**: [Adding langchain samples](https://github.com/HoussemDellai/ai-course/issues/2)\n",
      "   - **State**: Closed\n",
      "   - **Labels**: Bug, Documentation, Question\n",
      "   - **Created On**: March 7, 2025\n",
      "   - **Closed On**: March 7, 2025\n",
      "\n",
      "This is the only closed issue within the past week.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"List the top 10 issues closed within the last week.\"\n",
    "\n",
    "history.add_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "\n",
    "arguments = KernelArguments(now=datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "async for response in agent.invoke(history=history, arguments=arguments):\n",
    "    print(f\"{response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How were these issues labeled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The issue that was closed within the last week, titled \"Adding langchain samples,\" was labeled with the following tags:\n",
      "\n",
      "1. **bug**: Something isn't working\n",
      "2. **documentation**: Improvements or additions to documentation\n",
      "3. **question**: Further information is requested\n"
     ]
    }
   ],
   "source": [
    "user_input = \"How were these issues labeled?\"\n",
    "\n",
    "history.add_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "\n",
    "arguments = KernelArguments(now=datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "async for response in agent.invoke(history=history, arguments=arguments):\n",
    "    print(f\"{response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the 5 most recently opened issues with the \"Bug\" label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUEST: /repos/HoussemDellai/ai-course/issues?state=open&labels=bug&per_page=5&\n",
      "\n",
      "Here is the most recently opened issue with the 'Bug' label:\n",
      "\n",
      "1. **Issue #1**: [Creating issue just for testing in a chat agent](https://github.com/HoussemDellai/ai-course/issues/1)\n",
      "   - **State**: Open\n",
      "   - **Labels**: Bug\n",
      "   - **Created On**: March 7, 2025\n",
      "   - **Description**: This issue was likely created for testing purposes.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"List the 5 most recently opened issues with the 'Bug' label.\"\n",
    "\n",
    "history.add_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "\n",
    "arguments = KernelArguments(now=datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "async for response in agent.invoke(history=history, arguments=arguments):\n",
    "    print(f\"{response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More resources\n",
    "\n",
    "https://learn.microsoft.com/en-us/semantic-kernel/frameworks/agent/examples/example-chat-agent?pivots=programming-language-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
